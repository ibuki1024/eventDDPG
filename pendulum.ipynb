{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/.pyenv/versions/3.6.6/lib/python3.6/site-packages/pandas/compat/__init__.py:84: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import concatenate, Dense, Input, Flatten\n",
    "from keras.optimizers import Adam\n",
    "import gym\n",
    "from rl.agents import eventDDPGAgent\n",
    "from rl.memory import SequentialMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Space: Box(1,)\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# GymのPendulum環境を作成\n",
    "env = gym.make(\"Pendulum-v0\")\n",
    "\n",
    "# 取りうる”打ち手”のアクション数と値の定義\n",
    "nb_actions = 2\n",
    "ACT_ID_TO_VALUE = {0: [-1], 1: [+1]}\n",
    "\n",
    "print(\"Action Space: %s\" % env.action_space)\n",
    "#action  dim = 1\n",
    "#critic dim = 3 with ??\n",
    "print( env.observation_space.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actor_net(a_shape, s_shape):\n",
    "    action_input = Input(shape=(1,)+s_shape)\n",
    "    x = Flatten()(action_input)\n",
    "    x = Dense(32, activation=\"relu\")(x)\n",
    "    x = Dense(16, activation=\"relu\")(x)\n",
    "    x = Dense(3, activation=\"tanh\")(x)\n",
    "    #x = Dense(a_shape[0], activation=\"linear\")(x)\n",
    "    actor = Model(inputs=action_input, outputs=x)\n",
    "    return actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def critic_net(a_shape , s_shape):\n",
    "    action_input = Input(a_shape)\n",
    "    observation_input = Input(shape=(1,)+s_shape)\n",
    "    flattened_observation = Flatten()(observation_input)\n",
    "    x = concatenate([action_input, flattened_observation])\n",
    "    x = Dense(32, activation=\"relu\")(x)\n",
    "    x = Dense(32, activation=\"relu\")(x)\n",
    "    x = Dense(1, activation=\"linear\")(x)\n",
    "    critic = Model(inputs=[action_input, observation_input], outputs=x)\n",
    "    return (critic, action_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent(a_shape, s_shape):\n",
    "    actor = actor_net(a_shape, s_shape)\n",
    "    critic,  critic_action_input = critic_net(a_shape, s_shape)\n",
    "    memory = SequentialMemory(limit = 50000, window_length = 1)\n",
    "    print('critic_action_input = ', critic_action_input)\n",
    "    agent = eventDDPGAgent(\n",
    "        a_shape[0],\n",
    "        actor,\n",
    "        critic,\n",
    "        critic_action_input,\n",
    "        memory\n",
    "    )\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0924 16:54:45.896171 140736146887552 deprecation_wrapper.py:119] From /Users/admin/.pyenv/versions/3.6.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0924 16:54:45.941265 140736146887552 deprecation_wrapper.py:119] From /Users/admin/.pyenv/versions/3.6.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0924 16:54:45.992090 140736146887552 deprecation_wrapper.py:119] From /Users/admin/.pyenv/versions/3.6.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4158: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0924 16:54:46.149750 140736146887552 deprecation_wrapper.py:119] From /Users/admin/.pyenv/versions/3.6.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0924 16:54:46.151180 140736146887552 deprecation_wrapper.py:119] From /Users/admin/.pyenv/versions/3.6.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network.py shape =  (None, 1, 3)\n",
      "network.py shape =  (None, 3)\n",
      "network.py shape =  (None, 1, 3)\n",
      "critic_action_input =  Tensor(\"input_2:0\", shape=(?, 3), dtype=float32)\n",
      "(1,) (3,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0924 16:54:46.559592 140736146887552 deprecation_wrapper.py:119] From /Users/admin/.pyenv/versions/3.6.6/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network.py shape =  (None, 1, 3)\n",
      "network.py shape =  (None, 3)\n",
      "network.py shape =  (None, 1, 3)\n",
      "Training for 100000 steps ...\n",
      "\n",
      "episode =  0\n",
      "Interval 1 (0 steps performed)\n",
      "  199/10000 [..............................] - ETA: 4:03 - reward: -5.9631\n",
      "episode =  1\n",
      "  399/10000 [>.............................] - ETA: 3:19 - reward: -6.9572\n",
      "episode =  2\n",
      "  599/10000 [>.............................] - ETA: 3:02 - reward: -6.7801\n",
      "episode =  3\n",
      "  797/10000 [=>............................] - ETA: 2:52 - reward: -6.6200\n",
      "episode =  4\n",
      "  999/10000 [=>............................] - ETA: 2:44 - reward: -6.5039\n",
      "episode =  5\n",
      " 1200/10000 [==>...........................] - ETA: 2:49 - reward: -6.4109\n",
      "episode =  6\n",
      " 1399/10000 [===>..........................] - ETA: 2:42 - reward: -6.3138\n",
      "episode =  7\n",
      " 1599/10000 [===>..........................] - ETA: 2:37 - reward: -6.3208\n",
      "episode =  8\n",
      " 1797/10000 [====>.........................] - ETA: 2:31 - reward: -6.1485\n",
      "episode =  9\n",
      " 1998/10000 [====>.........................] - ETA: 2:26 - reward: -6.2012\n",
      "episode =  10\n",
      " 2200/10000 [=====>........................] - ETA: 2:21 - reward: -6.2085\n",
      "episode =  11\n",
      " 2398/10000 [======>.......................] - ETA: 2:16 - reward: -6.4419\n",
      "episode =  12\n",
      " 2598/10000 [======>.......................] - ETA: 2:12 - reward: -6.4344\n",
      "episode =  13\n",
      " 2797/10000 [=======>......................] - ETA: 2:08 - reward: -6.4079\n",
      "episode =  14\n",
      " 2998/10000 [=======>......................] - ETA: 2:04 - reward: -6.3285\n",
      "episode =  15\n",
      " 3200/10000 [========>.....................] - ETA: 2:00 - reward: -6.4952\n",
      "episode =  16\n",
      " 3400/10000 [=========>....................] - ETA: 1:56 - reward: -6.6113\n",
      "episode =  17\n",
      " 3598/10000 [=========>....................] - ETA: 1:52 - reward: -6.5618\n",
      "episode =  18\n",
      " 3799/10000 [==========>...................] - ETA: 1:48 - reward: -6.5315\n",
      "episode =  19\n",
      " 3997/10000 [==========>...................] - ETA: 1:44 - reward: -6.4772\n",
      "episode =  20\n",
      " 4198/10000 [===========>..................] - ETA: 1:41 - reward: -6.4206\n",
      "episode =  21\n",
      " 4399/10000 [============>.................] - ETA: 1:37 - reward: -6.3980\n",
      "episode =  22\n",
      " 4598/10000 [============>.................] - ETA: 1:33 - reward: -6.3091\n",
      "episode =  23\n",
      " 4797/10000 [=============>................] - ETA: 1:30 - reward: -6.3066\n",
      "episode =  24\n",
      " 4999/10000 [=============>................] - ETA: 1:26 - reward: -6.3815\n",
      "episode =  25\n",
      " 5200/10000 [==============>...............] - ETA: 1:22 - reward: -6.4195\n",
      "episode =  26\n",
      " 5399/10000 [===============>..............] - ETA: 1:19 - reward: -6.4181\n",
      "episode =  27\n",
      " 5599/10000 [===============>..............] - ETA: 1:15 - reward: -6.4638\n",
      "episode =  28\n",
      " 5800/10000 [================>.............] - ETA: 1:12 - reward: -6.5061\n",
      "episode =  29\n",
      " 5997/10000 [================>.............] - ETA: 1:08 - reward: -6.5352\n",
      "episode =  30\n",
      " 6199/10000 [=================>............] - ETA: 1:05 - reward: -6.5642\n",
      "episode =  31\n",
      " 6400/10000 [==================>...........] - ETA: 1:01 - reward: -6.5733\n",
      "episode =  32\n",
      " 6598/10000 [==================>...........] - ETA: 58s - reward: -6.5968\n",
      "episode =  33\n",
      " 6799/10000 [===================>..........] - ETA: 54s - reward: -6.6025\n",
      "episode =  34\n",
      " 7000/10000 [====================>.........] - ETA: 51s - reward: -6.6091\n",
      "episode =  35\n",
      " 7199/10000 [====================>.........] - ETA: 47s - reward: -6.6150\n",
      "episode =  36\n",
      " 7400/10000 [=====================>........] - ETA: 44s - reward: -6.6287\n",
      "episode =  37\n",
      " 7599/10000 [=====================>........] - ETA: 41s - reward: -6.6472\n",
      "episode =  38\n",
      " 7800/10000 [======================>.......] - ETA: 37s - reward: -6.6578\n",
      "episode =  39\n",
      " 7998/10000 [======================>.......] - ETA: 34s - reward: -6.6447\n",
      "episode =  40\n",
      " 8198/10000 [=======================>......] - ETA: 30s - reward: -6.6602\n",
      "episode =  41\n",
      " 8397/10000 [========================>.....] - ETA: 27s - reward: -6.6502\n",
      "episode =  42\n",
      " 8599/10000 [========================>.....] - ETA: 23s - reward: -6.6330\n",
      "episode =  43\n",
      " 8794/10000 [=========================>....] - ETA: 20s - reward: -6.6354\n",
      "episode =  44\n",
      " 8998/10000 [=========================>....] - ETA: 16s - reward: -6.6582\n",
      "episode =  45\n",
      " 9197/10000 [==========================>...] - ETA: 13s - reward: -6.6476\n",
      "episode =  46\n",
      " 9398/10000 [===========================>..] - ETA: 9s - reward: -6.6488\n",
      "episode =  47\n",
      " 9593/10000 [===========================>..] - ETA: 6s - reward: -6.6476\n",
      "episode =  48\n",
      " 9800/10000 [============================>.] - ETA: 3s - reward: -6.6902\n",
      "episode =  49\n",
      "10000/10000 [==============================] - 160s 16ms/step - reward: -6.7009\n",
      "\n",
      "episode =  50\n",
      "50 episodes - episode_reward: -1340.186 [-1807.815, -867.529] - loss: 2.340 - mean_absolute_error: 0.452 - mean_q: -27.871\n",
      "\n",
      "Interval 2 (10000 steps performed)\n",
      "  200/10000 [..............................] - ETA: 2:42 - reward: -6.6966\n",
      "episode =  51\n",
      "  398/10000 [>.............................] - ETA: 2:39 - reward: -6.8390\n",
      "episode =  52\n",
      "  598/10000 [>.............................] - ETA: 2:36 - reward: -6.5222\n",
      "episode =  53\n",
      "  800/10000 [=>............................] - ETA: 2:33 - reward: -5.9872\n",
      "episode =  54\n",
      "  999/10000 [=>............................] - ETA: 2:29 - reward: -6.1632\n",
      "episode =  55\n",
      " 1197/10000 [==>...........................] - ETA: 2:26 - reward: -6.1528\n",
      "episode =  56\n",
      " 1399/10000 [===>..........................] - ETA: 2:23 - reward: -6.1098\n",
      "episode =  57\n",
      " 1597/10000 [===>..........................] - ETA: 2:20 - reward: -6.1853\n",
      "episode =  58\n",
      " 1800/10000 [====>.........................] - ETA: 2:16 - reward: -6.0915\n",
      "episode =  59\n",
      " 2000/10000 [=====>........................] - ETA: 2:13 - reward: -6.1488\n",
      "episode =  60\n",
      " 2200/10000 [=====>........................] - ETA: 2:09 - reward: -6.1181\n",
      "episode =  61\n",
      " 2397/10000 [======>.......................] - ETA: 2:06 - reward: -6.0509\n",
      "episode =  62\n",
      " 2599/10000 [======>.......................] - ETA: 2:03 - reward: -6.0882\n",
      "episode =  63\n",
      " 2800/10000 [=======>......................] - ETA: 1:59 - reward: -6.0698\n",
      "episode =  64\n",
      " 2998/10000 [=======>......................] - ETA: 1:56 - reward: -6.2418\n",
      "episode =  65\n",
      " 3199/10000 [========>.....................] - ETA: 1:53 - reward: -6.2060\n",
      "episode =  66\n",
      " 3397/10000 [=========>....................] - ETA: 1:50 - reward: -6.1976\n",
      "episode =  67\n",
      " 3599/10000 [=========>....................] - ETA: 1:46 - reward: -6.1681\n",
      "episode =  68\n",
      " 3798/10000 [==========>...................] - ETA: 1:43 - reward: -6.1346\n",
      "episode =  69\n",
      " 3998/10000 [==========>...................] - ETA: 1:40 - reward: -6.1480\n",
      "episode =  70\n",
      " 4197/10000 [===========>..................] - ETA: 1:36 - reward: -6.0925\n",
      "episode =  71\n",
      " 4399/10000 [============>.................] - ETA: 1:33 - reward: -6.0181\n",
      "episode =  72\n",
      " 4600/10000 [============>.................] - ETA: 1:29 - reward: -5.9738\n",
      "episode =  73\n",
      " 4797/10000 [=============>................] - ETA: 1:26 - reward: -5.9623\n",
      "episode =  74\n",
      " 5000/10000 [==============>...............] - ETA: 1:23 - reward: -5.9679\n",
      "episode =  75\n",
      " 5198/10000 [==============>...............] - ETA: 1:20 - reward: -5.9449\n",
      "episode =  76\n",
      " 5397/10000 [===============>..............] - ETA: 1:16 - reward: -5.9440\n",
      "episode =  77\n",
      " 5600/10000 [===============>..............] - ETA: 1:13 - reward: -6.0402\n",
      "episode =  78\n",
      " 5797/10000 [================>.............] - ETA: 1:10 - reward: -6.0966\n",
      "episode =  79\n",
      " 5999/10000 [================>.............] - ETA: 1:06 - reward: -6.1553\n",
      "episode =  80\n",
      " 6200/10000 [=================>............] - ETA: 1:03 - reward: -6.0969\n",
      "episode =  81\n",
      " 6397/10000 [==================>...........] - ETA: 1:00 - reward: -6.0244\n",
      "episode =  82\n",
      " 6599/10000 [==================>...........] - ETA: 56s - reward: -6.0987\n",
      "episode =  83\n",
      " 6799/10000 [===================>..........] - ETA: 53s - reward: -6.0139\n",
      "episode =  84\n",
      " 6999/10000 [===================>..........] - ETA: 50s - reward: -6.0034\n",
      "episode =  85\n",
      " 7200/10000 [====================>.........] - ETA: 46s - reward: -5.9368\n",
      "episode =  86\n",
      " 7398/10000 [=====================>........] - ETA: 43s - reward: -5.8800\n",
      "episode =  87\n",
      " 7599/10000 [=====================>........] - ETA: 40s - reward: -5.8075\n",
      "episode =  88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 7798/10000 [======================>.......] - ETA: 36s - reward: -5.7294\n",
      "episode =  89\n",
      " 7999/10000 [======================>.......] - ETA: 33s - reward: -5.6814\n",
      "episode =  90\n",
      " 8198/10000 [=======================>......] - ETA: 30s - reward: -5.6211\n",
      "episode =  91\n",
      " 8400/10000 [========================>.....] - ETA: 26s - reward: -5.5755\n",
      "episode =  92\n",
      " 8598/10000 [========================>.....] - ETA: 23s - reward: -5.5388\n",
      "episode =  93\n",
      " 8799/10000 [=========================>....] - ETA: 20s - reward: -5.5130\n",
      "episode =  94\n",
      " 8997/10000 [=========================>....] - ETA: 16s - reward: -5.4873\n",
      "episode =  95\n",
      " 9198/10000 [==========================>...] - ETA: 13s - reward: -5.4515\n",
      "episode =  96\n",
      " 9400/10000 [===========================>..] - ETA: 10s - reward: -5.4169\n",
      "episode =  97\n",
      " 9600/10000 [===========================>..] - ETA: 6s - reward: -5.3806\n",
      "episode =  98\n",
      " 9798/10000 [============================>.] - ETA: 3s - reward: -5.3661\n",
      "episode =  99\n",
      "10000/10000 [==============================] - 167s 17ms/step - reward: -5.3256\n",
      "\n",
      "episode =  100\n",
      "50 episodes - episode_reward: -1065.114 [-1733.314, -569.502] - loss: 13.860 - mean_absolute_error: 0.913 - mean_q: -74.158\n",
      "\n",
      "Interval 3 (20000 steps performed)\n",
      "  197/10000 [..............................] - ETA: 2:42 - reward: -8.1160\n",
      "episode =  101\n",
      "  399/10000 [>.............................] - ETA: 2:39 - reward: -6.8585\n",
      "episode =  102\n",
      "  597/10000 [>.............................] - ETA: 2:36 - reward: -5.6582\n",
      "episode =  103\n",
      "  797/10000 [=>............................] - ETA: 2:33 - reward: -5.1942\n",
      "episode =  104\n",
      " 1000/10000 [==>...........................] - ETA: 2:29 - reward: -5.0361\n",
      "episode =  105\n",
      " 1198/10000 [==>...........................] - ETA: 2:26 - reward: -4.8273\n",
      "episode =  106\n",
      " 1398/10000 [===>..........................] - ETA: 2:23 - reward: -4.6775\n",
      "episode =  107\n",
      " 1600/10000 [===>..........................] - ETA: 2:19 - reward: -4.5502\n",
      "episode =  108\n",
      " 1798/10000 [====>.........................] - ETA: 2:16 - reward: -4.4734\n",
      "episode =  109\n",
      " 1998/10000 [====>.........................] - ETA: 2:13 - reward: -4.5176\n",
      "episode =  110\n",
      " 2199/10000 [=====>........................] - ETA: 2:09 - reward: -4.4292\n",
      "episode =  111\n",
      " 2399/10000 [======>.......................] - ETA: 2:06 - reward: -4.3664\n",
      "episode =  112\n",
      " 2599/10000 [======>.......................] - ETA: 2:03 - reward: -4.2772\n",
      "episode =  113\n",
      " 2799/10000 [=======>......................] - ETA: 2:00 - reward: -4.3220\n",
      "episode =  114\n",
      " 3000/10000 [========>.....................] - ETA: 1:56 - reward: -4.3182\n",
      "episode =  115\n",
      " 3199/10000 [========>.....................] - ETA: 1:55 - reward: -4.3192\n",
      "episode =  116\n",
      " 3398/10000 [=========>....................] - ETA: 1:52 - reward: -4.2401\n",
      "episode =  117\n",
      " 3599/10000 [=========>....................] - ETA: 1:48 - reward: -4.2507\n",
      "episode =  118\n",
      " 3800/10000 [==========>...................] - ETA: 1:45 - reward: -4.1588\n",
      "episode =  119\n",
      " 3999/10000 [==========>...................] - ETA: 1:41 - reward: -4.1414\n",
      "episode =  120\n",
      " 4199/10000 [===========>..................] - ETA: 1:38 - reward: -4.0937\n",
      "episode =  121\n",
      " 4398/10000 [============>.................] - ETA: 1:34 - reward: -4.0511\n",
      "episode =  122\n",
      " 4600/10000 [============>.................] - ETA: 1:31 - reward: -3.9945\n",
      "episode =  123\n",
      " 4798/10000 [=============>................] - ETA: 1:27 - reward: -3.9851\n",
      "episode =  124\n",
      " 4999/10000 [=============>................] - ETA: 1:24 - reward: -3.9507\n",
      "episode =  125\n",
      " 5199/10000 [==============>...............] - ETA: 1:21 - reward: -3.9845\n",
      "episode =  126\n",
      " 5397/10000 [===============>..............] - ETA: 1:17 - reward: -4.0227\n",
      "episode =  127\n",
      " 5598/10000 [===============>..............] - ETA: 1:14 - reward: -4.0775\n",
      "episode =  128\n",
      " 5800/10000 [================>.............] - ETA: 1:10 - reward: -4.1088\n",
      "episode =  129\n",
      " 6000/10000 [=================>............] - ETA: 1:07 - reward: -4.0563\n",
      "episode =  130\n",
      " 6200/10000 [=================>............] - ETA: 1:04 - reward: -4.0435\n",
      "episode =  131\n",
      " 6398/10000 [==================>...........] - ETA: 1:00 - reward: -4.0724\n",
      "episode =  132\n",
      " 6600/10000 [==================>...........] - ETA: 57s - reward: -4.0988\n",
      "episode =  133\n",
      " 6800/10000 [===================>..........] - ETA: 53s - reward: -4.1266\n",
      "episode =  134\n",
      " 6997/10000 [===================>..........] - ETA: 50s - reward: -4.1716\n",
      "episode =  135\n",
      " 7200/10000 [====================>.........] - ETA: 47s - reward: -4.1966\n",
      "episode =  136\n",
      " 7399/10000 [=====================>........] - ETA: 43s - reward: -4.2018\n",
      "episode =  137\n",
      " 7598/10000 [=====================>........] - ETA: 40s - reward: -4.1250\n",
      "episode =  138\n",
      " 7799/10000 [======================>.......] - ETA: 36s - reward: -4.0980\n",
      "episode =  139\n",
      " 7999/10000 [======================>.......] - ETA: 33s - reward: -4.1036\n",
      "episode =  140\n",
      " 8198/10000 [=======================>......] - ETA: 30s - reward: -4.1242\n",
      "episode =  141\n",
      " 8398/10000 [========================>.....] - ETA: 26s - reward: -4.0409\n",
      "episode =  142\n",
      " 8599/10000 [========================>.....] - ETA: 23s - reward: -4.0471\n",
      "episode =  143\n",
      " 8800/10000 [=========================>....] - ETA: 20s - reward: -3.9687\n",
      "episode =  144\n",
      " 8998/10000 [=========================>....] - ETA: 16s - reward: -3.9642\n",
      "episode =  145\n",
      " 9199/10000 [==========================>...] - ETA: 13s - reward: -3.9310\n",
      "episode =  146\n",
      " 9398/10000 [===========================>..] - ETA: 10s - reward: -3.8478\n",
      "episode =  147\n",
      " 9600/10000 [===========================>..] - ETA: 6s - reward: -3.7798\n",
      "episode =  148\n",
      " 9798/10000 [============================>.] - ETA: 3s - reward: -3.7291\n",
      "episode =  149\n",
      "10000/10000 [==============================] - 168s 17ms/step - reward: -3.7302\n",
      "\n",
      "episode =  150\n",
      "50 episodes - episode_reward: -746.033 [-1609.821, -0.916] - loss: 25.251 - mean_absolute_error: 1.588 - mean_q: -100.668\n",
      "\n",
      "Interval 4 (30000 steps performed)\n",
      "  198/10000 [..............................] - ETA: 2:42 - reward: -3.1529\n",
      "episode =  151\n",
      "  400/10000 [>.............................] - ETA: 2:39 - reward: -1.5655\n",
      "episode =  152\n",
      "  597/10000 [>.............................] - ETA: 2:36 - reward: -1.4629\n",
      "episode =  153\n",
      "  798/10000 [=>............................] - ETA: 2:33 - reward: -1.8573\n",
      "episode =  154\n",
      "  999/10000 [=>............................] - ETA: 2:29 - reward: -2.4784\n",
      "episode =  155\n",
      " 1199/10000 [==>...........................] - ETA: 2:26 - reward: -3.0152\n",
      "episode =  156\n",
      " 1399/10000 [===>..........................] - ETA: 2:23 - reward: -3.4500\n",
      "episode =  157\n",
      " 1598/10000 [===>..........................] - ETA: 2:19 - reward: -3.0983\n",
      "episode =  158\n",
      " 1800/10000 [====>.........................] - ETA: 2:16 - reward: -3.0225\n",
      "episode =  159\n",
      " 1998/10000 [====>.........................] - ETA: 2:13 - reward: -3.0863\n",
      "episode =  160\n",
      " 2199/10000 [=====>........................] - ETA: 2:09 - reward: -3.4060\n",
      "episode =  161\n",
      " 2398/10000 [======>.......................] - ETA: 2:06 - reward: -3.2276\n",
      "episode =  162\n",
      " 2599/10000 [======>.......................] - ETA: 2:03 - reward: -3.0724\n",
      "episode =  163\n",
      " 2798/10000 [=======>......................] - ETA: 2:00 - reward: -3.3931\n",
      "episode =  164\n",
      " 2997/10000 [=======>......................] - ETA: 1:56 - reward: -3.4994\n",
      "episode =  165\n",
      " 3198/10000 [========>.....................] - ETA: 1:53 - reward: -3.6359\n",
      "episode =  166\n",
      " 3398/10000 [=========>....................] - ETA: 1:50 - reward: -3.7289\n",
      "episode =  167\n",
      " 3599/10000 [=========>....................] - ETA: 1:46 - reward: -3.9079\n",
      "episode =  168\n",
      " 3798/10000 [==========>...................] - ETA: 1:43 - reward: -3.7691\n",
      "episode =  169\n",
      " 3999/10000 [==========>...................] - ETA: 1:40 - reward: -3.7918\n",
      "episode =  170\n",
      " 4199/10000 [===========>..................] - ETA: 1:36 - reward: -3.8739\n",
      "episode =  171\n",
      " 4397/10000 [============>.................] - ETA: 1:33 - reward: -4.0092\n",
      "episode =  172\n",
      " 4597/10000 [============>.................] - ETA: 1:30 - reward: -4.1900\n",
      "episode =  173\n",
      " 4799/10000 [=============>................] - ETA: 1:26 - reward: -4.2454\n",
      "episode =  174\n",
      " 5000/10000 [==============>...............] - ETA: 1:23 - reward: -4.2444\n",
      "episode =  175\n",
      " 5200/10000 [==============>...............] - ETA: 1:19 - reward: -4.3441\n",
      "episode =  176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5400/10000 [===============>..............] - ETA: 1:16 - reward: -4.3787\n",
      "episode =  177\n",
      " 5598/10000 [===============>..............] - ETA: 1:13 - reward: -4.4397\n",
      "episode =  178\n",
      " 5799/10000 [================>.............] - ETA: 1:10 - reward: -4.4979\n",
      "episode =  179\n",
      " 6000/10000 [=================>............] - ETA: 1:06 - reward: -4.5686\n",
      "episode =  180\n",
      " 6199/10000 [=================>............] - ETA: 1:03 - reward: -4.4616\n",
      "episode =  181\n",
      " 6398/10000 [==================>...........] - ETA: 1:00 - reward: -4.3798\n",
      "episode =  182\n",
      " 6599/10000 [==================>...........] - ETA: 56s - reward: -4.4502\n",
      "episode =  183\n",
      " 6798/10000 [===================>..........] - ETA: 53s - reward: -4.4106\n",
      "episode =  184\n",
      " 6999/10000 [===================>..........] - ETA: 50s - reward: -4.4380\n",
      "episode =  185\n",
      " 7197/10000 [====================>.........] - ETA: 46s - reward: -4.4772\n",
      "episode =  186\n",
      " 7400/10000 [=====================>........] - ETA: 43s - reward: -4.4407\n",
      "episode =  187\n",
      " 7597/10000 [=====================>........] - ETA: 40s - reward: -4.4938\n",
      "episode =  188\n",
      " 7797/10000 [======================>.......] - ETA: 36s - reward: -4.4754\n",
      "episode =  189\n",
      " 7998/10000 [======================>.......] - ETA: 33s - reward: -4.3936\n",
      "episode =  190\n",
      " 8199/10000 [=======================>......] - ETA: 30s - reward: -4.4286\n",
      "episode =  191\n",
      " 8399/10000 [========================>.....] - ETA: 26s - reward: -4.4554\n",
      "episode =  192\n",
      " 8600/10000 [========================>.....] - ETA: 23s - reward: -4.3952\n",
      "episode =  193\n",
      " 8800/10000 [=========================>....] - ETA: 20s - reward: -4.4450\n",
      "episode =  194\n",
      " 9000/10000 [==========================>...] - ETA: 16s - reward: -4.4883\n",
      "episode =  195\n",
      " 9198/10000 [==========================>...] - ETA: 13s - reward: -4.5144\n",
      "episode =  196\n",
      " 9399/10000 [===========================>..] - ETA: 10s - reward: -4.5513\n",
      "episode =  197\n",
      " 9598/10000 [===========================>..] - ETA: 6s - reward: -4.5968\n",
      "episode =  198\n",
      " 9798/10000 [============================>.] - ETA: 3s - reward: -4.6316\n",
      "episode =  199\n",
      "10000/10000 [==============================] - 167s 17ms/step - reward: -4.6658\n",
      "\n",
      "episode =  200\n",
      "50 episodes - episode_reward: -933.163 [-1644.734, -1.928] - loss: 36.580 - mean_absolute_error: 1.962 - mean_q: -113.680\n",
      "\n",
      "Interval 5 (40000 steps performed)\n",
      "  200/10000 [..............................] - ETA: 2:43 - reward: -3.6654\n",
      "episode =  201\n",
      "  400/10000 [>.............................] - ETA: 2:39 - reward: -4.9683\n",
      "episode =  202\n",
      "  600/10000 [>.............................] - ETA: 2:36 - reward: -4.5589\n",
      "episode =  203\n",
      "  800/10000 [=>............................] - ETA: 2:33 - reward: -4.0362\n",
      "episode =  204\n",
      "  998/10000 [=>............................] - ETA: 2:30 - reward: -4.5754\n",
      "episode =  205\n",
      " 1200/10000 [==>...........................] - ETA: 2:26 - reward: -4.3455\n",
      "episode =  206\n",
      " 1399/10000 [===>..........................] - ETA: 2:23 - reward: -4.3627\n",
      "episode =  207\n",
      " 1597/10000 [===>..........................] - ETA: 2:20 - reward: -4.3060\n",
      "episode =  208\n",
      " 1800/10000 [====>.........................] - ETA: 2:16 - reward: -4.4772\n",
      "episode =  209\n",
      " 1999/10000 [====>.........................] - ETA: 2:13 - reward: -4.2087\n",
      "episode =  210\n",
      " 2199/10000 [=====>........................] - ETA: 2:10 - reward: -3.8823\n",
      "episode =  211\n",
      " 2398/10000 [======>.......................] - ETA: 2:06 - reward: -3.7091\n",
      "episode =  212\n",
      " 2599/10000 [======>.......................] - ETA: 2:03 - reward: -3.9286\n",
      "episode =  213\n",
      " 2800/10000 [=======>......................] - ETA: 2:00 - reward: -3.7354\n",
      "episode =  214\n",
      " 2999/10000 [=======>......................] - ETA: 1:56 - reward: -3.5666\n",
      "episode =  215\n",
      " 3198/10000 [========>.....................] - ETA: 1:53 - reward: -3.4572\n",
      "episode =  216\n",
      " 3399/10000 [=========>....................] - ETA: 1:50 - reward: -3.5698\n",
      "episode =  217\n",
      " 3600/10000 [=========>....................] - ETA: 1:46 - reward: -3.5102\n",
      "episode =  218\n",
      " 3798/10000 [==========>...................] - ETA: 1:43 - reward: -3.6277\n",
      "episode =  219\n",
      " 3999/10000 [==========>...................] - ETA: 1:40 - reward: -3.7407\n",
      "episode =  220\n",
      " 4198/10000 [===========>..................] - ETA: 1:36 - reward: -3.7091\n",
      "episode =  221\n",
      " 4397/10000 [============>.................] - ETA: 1:33 - reward: -3.5415\n",
      "episode =  222\n",
      " 4600/10000 [============>.................] - ETA: 1:30 - reward: -3.6158\n",
      "episode =  223\n",
      " 4800/10000 [=============>................] - ETA: 1:26 - reward: -3.4654\n",
      "episode =  224\n",
      " 4999/10000 [=============>................] - ETA: 1:23 - reward: -3.5313\n",
      "episode =  225\n",
      " 5198/10000 [==============>...............] - ETA: 1:20 - reward: -3.6557\n",
      "episode =  226\n",
      " 5400/10000 [===============>..............] - ETA: 1:16 - reward: -3.6880\n",
      "episode =  227\n",
      " 5600/10000 [===============>..............] - ETA: 1:13 - reward: -3.7419\n",
      "episode =  228\n",
      " 5797/10000 [================>.............] - ETA: 1:10 - reward: -3.8138\n",
      "episode =  229\n",
      " 6000/10000 [=================>............] - ETA: 1:06 - reward: -3.8810\n",
      "episode =  230\n",
      " 6200/10000 [=================>............] - ETA: 1:03 - reward: -3.9403\n",
      "episode =  231\n",
      " 6398/10000 [==================>...........] - ETA: 1:00 - reward: -4.0044\n",
      "episode =  232\n",
      " 6600/10000 [==================>...........] - ETA: 56s - reward: -4.0231\n",
      "episode =  233\n",
      " 6797/10000 [===================>..........] - ETA: 53s - reward: -4.0422\n",
      "episode =  234\n",
      " 6999/10000 [===================>..........] - ETA: 50s - reward: -4.0617\n",
      "episode =  235\n",
      " 7200/10000 [====================>.........] - ETA: 46s - reward: -4.0698\n",
      "episode =  236\n",
      " 7397/10000 [=====================>........] - ETA: 43s - reward: -4.1122\n",
      "episode =  237\n",
      " 7599/10000 [=====================>........] - ETA: 40s - reward: -4.1463\n",
      "episode =  238\n",
      " 7798/10000 [======================>.......] - ETA: 36s - reward: -4.1912\n",
      "episode =  239\n",
      " 7999/10000 [======================>.......] - ETA: 33s - reward: -4.1988\n",
      "episode =  240\n",
      " 8198/10000 [=======================>......] - ETA: 30s - reward: -4.2084\n",
      "episode =  241\n",
      " 8400/10000 [========================>.....] - ETA: 26s - reward: -4.2308\n",
      "episode =  242\n",
      " 8598/10000 [========================>.....] - ETA: 23s - reward: -4.2055\n",
      "episode =  243\n",
      " 8799/10000 [=========================>....] - ETA: 20s - reward: -4.1814\n",
      "episode =  244\n",
      " 8999/10000 [=========================>....] - ETA: 16s - reward: -4.2137\n",
      "episode =  245\n",
      " 9198/10000 [==========================>...] - ETA: 13s - reward: -4.2078\n",
      "episode =  246\n",
      " 9399/10000 [===========================>..] - ETA: 10s - reward: -4.1432\n",
      "episode =  247\n",
      " 9599/10000 [===========================>..] - ETA: 6s - reward: -4.1911\n",
      "episode =  248\n",
      " 9799/10000 [============================>.] - ETA: 3s - reward: -4.2444\n",
      "episode =  249\n",
      "10000/10000 [==============================] - 167s 17ms/step - reward: -4.2075\n",
      "\n",
      "episode =  250\n",
      "50 episodes - episode_reward: -841.494 [-1366.205, -1.046] - loss: 45.073 - mean_absolute_error: 2.153 - mean_q: -122.613\n",
      "\n",
      "Interval 6 (50000 steps performed)\n",
      "  199/10000 [..............................] - ETA: 2:43 - reward: -1.2161\n",
      "episode =  251\n",
      "  399/10000 [>.............................] - ETA: 2:39 - reward: -2.1685\n",
      "episode =  252\n",
      "  598/10000 [>.............................] - ETA: 2:36 - reward: -1.8655\n",
      "episode =  253\n",
      "  800/10000 [=>............................] - ETA: 2:33 - reward: -1.5516\n",
      "episode =  254\n",
      "  999/10000 [=>............................] - ETA: 2:29 - reward: -1.4923\n",
      "episode =  255\n",
      " 1199/10000 [==>...........................] - ETA: 2:26 - reward: -1.3482\n",
      "episode =  256\n",
      " 1399/10000 [===>..........................] - ETA: 2:23 - reward: -1.7885\n",
      "episode =  257\n",
      " 1598/10000 [===>..........................] - ETA: 2:20 - reward: -1.5665\n",
      "episode =  258\n",
      " 1798/10000 [====>.........................] - ETA: 2:16 - reward: -1.4621\n",
      "episode =  259\n",
      " 1999/10000 [====>.........................] - ETA: 2:13 - reward: -1.9934\n",
      "episode =  260\n",
      " 2197/10000 [=====>........................] - ETA: 2:10 - reward: -1.9845\n",
      "episode =  261\n",
      " 2399/10000 [======>.......................] - ETA: 2:06 - reward: -2.0933\n",
      "episode =  262\n",
      " 2598/10000 [======>.......................] - ETA: 2:03 - reward: -2.2675\n",
      "episode =  263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2800/10000 [=======>......................] - ETA: 2:00 - reward: -2.3217\n",
      "episode =  264\n",
      " 3000/10000 [========>.....................] - ETA: 1:56 - reward: -2.3352\n",
      "episode =  265\n",
      " 3199/10000 [========>.....................] - ETA: 1:53 - reward: -2.2684\n",
      "episode =  266\n",
      " 3399/10000 [=========>....................] - ETA: 1:50 - reward: -2.2099\n",
      "episode =  267\n",
      " 3599/10000 [=========>....................] - ETA: 1:46 - reward: -2.2649\n",
      "episode =  268\n",
      " 3797/10000 [==========>...................] - ETA: 1:43 - reward: -2.2096\n",
      "episode =  269\n",
      " 3999/10000 [==========>...................] - ETA: 1:40 - reward: -2.1586\n",
      "episode =  270\n",
      " 4199/10000 [===========>..................] - ETA: 1:36 - reward: -2.2145\n",
      "episode =  271\n",
      " 4400/10000 [============>.................] - ETA: 1:33 - reward: -2.1407\n",
      "episode =  272\n",
      " 4599/10000 [============>.................] - ETA: 1:30 - reward: -2.0756\n",
      "episode =  273\n",
      " 4799/10000 [=============>................] - ETA: 1:26 - reward: -2.0157\n",
      "episode =  274\n",
      " 4999/10000 [=============>................] - ETA: 1:23 - reward: -2.0339\n",
      "episode =  275\n",
      " 5198/10000 [==============>...............] - ETA: 1:20 - reward: -1.9793\n",
      "episode =  276\n",
      " 5399/10000 [===============>..............] - ETA: 1:16 - reward: -2.0142\n",
      "episode =  277\n",
      " 5600/10000 [===============>..............] - ETA: 1:13 - reward: -2.0512\n",
      "episode =  278\n",
      " 5798/10000 [================>.............] - ETA: 1:10 - reward: -2.0722\n",
      "episode =  279\n",
      " 5998/10000 [================>.............] - ETA: 1:06 - reward: -2.0240\n",
      "episode =  280\n",
      " 6198/10000 [=================>............] - ETA: 1:03 - reward: -1.9784\n",
      "episode =  281\n",
      " 6400/10000 [==================>...........] - ETA: 1:00 - reward: -1.9546\n",
      "episode =  282\n",
      " 6598/10000 [==================>...........] - ETA: 56s - reward: -1.9152\n",
      "episode =  283\n",
      " 6799/10000 [===================>..........] - ETA: 53s - reward: -1.9125\n",
      "episode =  284\n",
      " 7000/10000 [====================>.........] - ETA: 50s - reward: -1.9273\n",
      "episode =  285\n",
      " 7200/10000 [====================>.........] - ETA: 46s - reward: -1.9410\n",
      "episode =  286\n",
      " 7398/10000 [=====================>........] - ETA: 43s - reward: -1.9232\n",
      "episode =  287\n",
      " 7597/10000 [=====================>........] - ETA: 40s - reward: -1.8895\n",
      "episode =  288\n",
      " 7798/10000 [======================>.......] - ETA: 36s - reward: -1.8571\n",
      "episode =  289\n",
      " 7998/10000 [======================>.......] - ETA: 33s - reward: -1.8558\n",
      "episode =  290\n",
      " 8198/10000 [=======================>......] - ETA: 30s - reward: -1.8558\n",
      "episode =  291\n",
      " 8400/10000 [========================>.....] - ETA: 26s - reward: -1.8415\n",
      "episode =  292\n",
      " 8597/10000 [========================>.....] - ETA: 23s - reward: -1.8280\n",
      "episode =  293\n",
      " 8798/10000 [=========================>....] - ETA: 20s - reward: -1.7999\n",
      "episode =  294\n",
      " 9000/10000 [==========================>...] - ETA: 16s - reward: -1.7731\n",
      "episode =  295\n",
      " 9200/10000 [==========================>...] - ETA: 13s - reward: -1.7619\n",
      "episode =  296\n",
      " 9398/10000 [===========================>..] - ETA: 10s - reward: -1.7761\n",
      "episode =  297\n",
      " 9598/10000 [===========================>..] - ETA: 6s - reward: -1.8044\n",
      "episode =  298\n",
      " 9798/10000 [============================>.] - ETA: 3s - reward: -1.8039\n",
      "episode =  299\n",
      "10000/10000 [==============================] - 167s 17ms/step - reward: -1.8049\n",
      "\n",
      "episode =  300\n",
      "50 episodes - episode_reward: -360.976 [-1363.887, -1.129] - loss: 41.285 - mean_absolute_error: 2.294 - mean_q: -114.445\n",
      "\n",
      "Interval 7 (60000 steps performed)\n",
      "  198/10000 [..............................] - ETA: 2:43 - reward: -2.4068\n",
      "episode =  301\n",
      "  399/10000 [>.............................] - ETA: 2:39 - reward: -2.5095\n",
      "episode =  302\n",
      "  599/10000 [>.............................] - ETA: 2:36 - reward: -1.8734\n",
      "episode =  303\n",
      "  800/10000 [=>............................] - ETA: 2:33 - reward: -1.7080\n",
      "episode =  304\n",
      "  998/10000 [=>............................] - ETA: 2:29 - reward: -1.4963\n",
      "episode =  305\n",
      " 1198/10000 [==>...........................] - ETA: 2:26 - reward: -1.6792\n",
      "episode =  306\n",
      " 1399/10000 [===>..........................] - ETA: 2:23 - reward: -1.5272\n",
      "episode =  307\n",
      " 1597/10000 [===>..........................] - ETA: 2:20 - reward: -1.4170\n",
      "episode =  308\n",
      " 1798/10000 [====>.........................] - ETA: 2:16 - reward: -1.3943\n",
      "episode =  309\n",
      " 1998/10000 [====>.........................] - ETA: 2:13 - reward: -1.5398\n",
      "episode =  310\n",
      " 2200/10000 [=====>........................] - ETA: 2:10 - reward: -1.4019\n",
      "episode =  311\n",
      " 2399/10000 [======>.......................] - ETA: 2:06 - reward: -1.3370\n",
      "episode =  312\n",
      " 2600/10000 [======>.......................] - ETA: 2:03 - reward: -1.4257\n",
      "episode =  313\n",
      " 2800/10000 [=======>......................] - ETA: 2:00 - reward: -1.4120\n",
      "episode =  314\n",
      " 2999/10000 [=======>......................] - ETA: 1:56 - reward: -1.4381\n",
      "episode =  315\n",
      " 3199/10000 [========>.....................] - ETA: 1:53 - reward: -1.4270\n",
      "episode =  316\n",
      " 3399/10000 [=========>....................] - ETA: 1:50 - reward: -1.4166\n",
      "episode =  317\n",
      " 3599/10000 [=========>....................] - ETA: 1:46 - reward: -1.5363\n",
      "episode =  318\n",
      " 3800/10000 [==========>...................] - ETA: 1:43 - reward: -1.6484\n",
      "episode =  319\n",
      " 4000/10000 [===========>..................] - ETA: 1:40 - reward: -1.6291\n",
      "episode =  320\n",
      " 4198/10000 [===========>..................] - ETA: 1:36 - reward: -1.5808\n",
      "episode =  321\n",
      " 4399/10000 [============>.................] - ETA: 1:33 - reward: -1.5653\n",
      "episode =  322\n",
      " 4600/10000 [============>.................] - ETA: 1:30 - reward: -1.5767\n",
      "episode =  323\n",
      " 4799/10000 [=============>................] - ETA: 1:26 - reward: -1.6661\n",
      "episode =  324\n",
      " 4998/10000 [=============>................] - ETA: 1:23 - reward: -1.6243\n",
      "episode =  325\n",
      " 5200/10000 [==============>...............] - ETA: 1:20 - reward: -1.6552\n",
      "episode =  326\n",
      " 5398/10000 [===============>..............] - ETA: 1:16 - reward: -1.6609\n",
      "episode =  327\n",
      " 5599/10000 [===============>..............] - ETA: 1:13 - reward: -1.6993\n",
      "episode =  328\n",
      " 5799/10000 [================>.............] - ETA: 1:10 - reward: -1.7259\n",
      "episode =  329\n",
      " 5998/10000 [================>.............] - ETA: 1:06 - reward: -1.6905\n",
      "episode =  330\n",
      " 6199/10000 [=================>............] - ETA: 1:03 - reward: -1.6554\n",
      "episode =  331\n",
      " 6399/10000 [==================>...........] - ETA: 1:00 - reward: -1.6230\n",
      "episode =  332\n",
      " 6598/10000 [==================>...........] - ETA: 56s - reward: -1.5931\n",
      "episode =  333\n",
      " 6798/10000 [===================>..........] - ETA: 53s - reward: -1.5983\n",
      "episode =  334\n",
      " 6997/10000 [===================>..........] - ETA: 50s - reward: -1.6416\n",
      "episode =  335\n",
      " 7200/10000 [====================>.........] - ETA: 46s - reward: -1.6641\n",
      "episode =  336\n",
      " 7400/10000 [=====================>........] - ETA: 43s - reward: -1.6518\n",
      "episode =  337\n",
      " 7599/10000 [=====================>........] - ETA: 40s - reward: -1.6724\n",
      "episode =  338\n",
      " 7798/10000 [======================>.......] - ETA: 36s - reward: -1.6302\n",
      "episode =  339\n",
      " 7999/10000 [======================>.......] - ETA: 33s - reward: -1.6048\n",
      "episode =  340\n",
      " 8198/10000 [=======================>......] - ETA: 30s - reward: -1.6426\n",
      "episode =  341\n",
      " 8400/10000 [========================>.....] - ETA: 26s - reward: -1.6178\n",
      "episode =  342\n",
      " 8600/10000 [========================>.....] - ETA: 23s - reward: -1.5945\n",
      "episode =  343\n",
      " 8798/10000 [=========================>....] - ETA: 20s - reward: -1.6497\n",
      "episode =  344\n",
      " 9000/10000 [==========================>...] - ETA: 16s - reward: -1.6296\n",
      "episode =  345\n",
      " 9197/10000 [==========================>...] - ETA: 13s - reward: -1.6205\n",
      "episode =  346\n",
      " 9400/10000 [===========================>..] - ETA: 10s - reward: -1.5986\n",
      "episode =  347\n",
      " 9599/10000 [===========================>..] - ETA: 6s - reward: -1.6047\n",
      "episode =  348\n",
      " 9800/10000 [============================>.] - ETA: 3s - reward: -1.5843\n",
      "episode =  349\n",
      "10000/10000 [==============================] - 168s 17ms/step - reward: -1.5882\n",
      "\n",
      "episode =  350\n",
      "50 episodes - episode_reward: -317.631 [-827.260, -3.488] - loss: 25.350 - mean_absolute_error: 2.378 - mean_q: -85.175\n",
      "\n",
      "Interval 8 (70000 steps performed)\n",
      "  199/10000 [..............................] - ETA: 1:25 - reward: -1.7769\n",
      "episode =  351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  396/10000 [>.............................] - ETA: 1:16 - reward: -2.9885\n",
      "episode =  352\n",
      "  599/10000 [>.............................] - ETA: 1:11 - reward: -3.3055\n",
      "episode =  353\n",
      "  796/10000 [=>............................] - ETA: 1:07 - reward: -2.6460\n",
      "episode =  354\n",
      " 1000/10000 [==>...........................] - ETA: 1:04 - reward: -2.1094\n",
      "episode =  355\n",
      " 1199/10000 [==>...........................] - ETA: 1:02 - reward: -2.1674\n",
      "episode =  356\n",
      " 1396/10000 [===>..........................] - ETA: 1:00 - reward: -2.1217\n",
      "episode =  357\n",
      " 1595/10000 [===>..........................] - ETA: 59s - reward: -1.9366\n",
      "episode =  358\n",
      " 1799/10000 [====>.........................] - ETA: 57s - reward: -1.8510\n",
      "episode =  359\n",
      " 1994/10000 [====>.........................] - ETA: 56s - reward: -1.8583\n",
      "episode =  360\n",
      " 2199/10000 [=====>........................] - ETA: 59:41 - reward: -1.7428\n",
      "episode =  361\n",
      " 2400/10000 [======>.......................] - ETA: 53:33 - reward: -1.6483\n",
      "episode =  362\n",
      " 2598/10000 [======>.......................] - ETA: 48:21 - reward: -1.5720\n",
      "episode =  363\n",
      " 2798/10000 [=======>......................] - ETA: 43:52 - reward: -1.5873\n",
      "episode =  364\n",
      " 2968/10000 [=======>......................] - ETA: 40:30 - reward: -1.6951\n",
      "episode =  365\n",
      "\n",
      "episode =  366\n",
      " 3400/10000 [=========>....................] - ETA: 33:12 - reward: -1.6558\n",
      "episode =  367\n",
      " 3599/10000 [=========>....................] - ETA: 30:32 - reward: -1.6627\n",
      "episode =  368\n",
      " 3800/10000 [==========>...................] - ETA: 28:06 - reward: -1.6687\n",
      "episode =  369\n",
      " 3998/10000 [==========>...................] - ETA: 25:56 - reward: -1.6494\n",
      "episode =  370\n",
      " 4200/10000 [===========>..................] - ETA: 23:56 - reward: -1.5991\n",
      "episode =  371\n",
      " 4398/10000 [============>.................] - ETA: 22:09 - reward: -1.8372\n",
      "episode =  372\n",
      " 4599/10000 [============>.................] - ETA: 20:30 - reward: -1.8398\n",
      "episode =  373\n",
      " 4800/10000 [=============>................] - ETA: 18:58 - reward: -1.8399\n",
      "episode =  374\n",
      " 4999/10000 [=============>................] - ETA: 17:34 - reward: -1.7916\n",
      "episode =  375\n",
      " 5198/10000 [==============>...............] - ETA: 16:17 - reward: -1.7468- E\n",
      "episode =  376\n",
      " 5398/10000 [===============>..............] - ETA: 15:04 - reward: -1.7265\n",
      "episode =  377\n",
      " 5599/10000 [===============>..............] - ETA: 13:56 - reward: -1.6862\n",
      "episode =  378\n",
      " 5800/10000 [================>.............] - ETA: 12:53 - reward: -1.7299\n",
      "episode =  379\n",
      " 6000/10000 [=================>............] - ETA: 11:54 - reward: -1.7314\n",
      "episode =  380\n",
      " 6200/10000 [=================>............] - ETA: 10:58 - reward: -1.8686\n",
      "episode =  381\n",
      " 6398/10000 [==================>...........] - ETA: 10:06 - reward: -1.9052\n",
      "episode =  382\n",
      " 6598/10000 [==================>...........] - ETA: 9:17 - reward: -1.9186\n",
      "episode =  383\n",
      " 6800/10000 [===================>..........] - ETA: 8:30 - reward: -1.8802\n",
      "episode =  384\n",
      " 6999/10000 [===================>..........] - ETA: 7:46 - reward: -1.8448\n",
      "episode =  385\n",
      " 7199/10000 [====================>.........] - ETA: 7:04 - reward: -1.8466\n",
      "episode =  386\n",
      " 7400/10000 [=====================>........] - ETA: 6:24 - reward: -1.8286\n",
      "episode =  387\n",
      " 7597/10000 [=====================>........] - ETA: 5:47 - reward: -1.8285\n",
      "episode =  388\n",
      " 7798/10000 [======================>.......] - ETA: 5:11 - reward: -1.8122\n",
      "episode =  389\n",
      " 8000/10000 [=======================>......] - ETA: 4:36 - reward: -1.7813\n",
      "episode =  390\n",
      " 8199/10000 [=======================>......] - ETA: 4:03 - reward: -1.8315\n",
      "episode =  391\n",
      " 8400/10000 [========================>.....] - ETA: 3:31 - reward: -1.8022\n",
      "episode =  392\n",
      " 8600/10000 [========================>.....] - ETA: 3:01 - reward: -1.8483\n",
      "episode =  393\n",
      " 8797/10000 [=========================>....] - ETA: 2:32 - reward: -1.8359\n",
      "episode =  394\n",
      " 8999/10000 [=========================>....] - ETA: 2:04 - reward: -1.8082\n",
      "episode =  395\n",
      " 9199/10000 [==========================>...] - ETA: 1:37 - reward: -1.8543\n",
      "episode =  396\n",
      " 9399/10000 [===========================>..] - ETA: 1:12 - reward: -1.9241\n",
      "episode =  397\n",
      " 9599/10000 [===========================>..] - ETA: 47s - reward: -1.9103\n",
      "episode =  398\n",
      " 9798/10000 [============================>.] - ETA: 23s - reward: -1.8966\n",
      "episode =  399\n",
      "10000/10000 [==============================] - 1138s 114ms/step - reward: -1.8705\n",
      "\n",
      "episode =  400\n",
      "50 episodes - episode_reward: -374.109 [-1382.737, -3.148] - loss: 17.866 - mean_absolute_error: 2.135 - mean_q: -65.649\n",
      "\n",
      "Interval 9 (80000 steps performed)\n",
      "  199/10000 [..............................] - ETA: 2:42 - reward: -2.4132\n",
      "episode =  401\n",
      "  399/10000 [>.............................] - ETA: 2:39 - reward: -2.3818\n",
      "episode =  402\n",
      "  597/10000 [>.............................] - ETA: 2:36 - reward: -2.5917\n",
      "episode =  403\n",
      "  798/10000 [=>............................] - ETA: 2:33 - reward: -2.6829\n",
      "episode =  404\n",
      "  997/10000 [=>............................] - ETA: 2:30 - reward: -2.5059\n",
      "episode =  405\n",
      " 1199/10000 [==>...........................] - ETA: 2:26 - reward: -2.6587\n",
      "episode =  406\n",
      " 1400/10000 [===>..........................] - ETA: 2:23 - reward: -2.6687\n",
      "episode =  407\n",
      " 1600/10000 [===>..........................] - ETA: 2:20 - reward: -3.0635\n",
      "episode =  408\n",
      " 1800/10000 [====>.........................] - ETA: 2:16 - reward: -2.8550\n",
      "episode =  409\n",
      " 1998/10000 [====>.........................] - ETA: 2:13 - reward: -2.6332\n",
      "episode =  410\n",
      " 2198/10000 [=====>........................] - ETA: 2:10 - reward: -2.4995\n",
      "episode =  411\n",
      " 2398/10000 [======>.......................] - ETA: 2:06 - reward: -2.4934\n",
      "episode =  412\n",
      " 2597/10000 [======>.......................] - ETA: 2:02 - reward: -2.5407\n",
      "episode =  413\n",
      " 2795/10000 [=======>......................] - ETA: 1:55 - reward: -2.4495\n",
      "episode =  414\n",
      " 2999/10000 [=======>......................] - ETA: 1:47 - reward: -2.3655\n",
      "episode =  415\n",
      " 3199/10000 [========>.....................] - ETA: 1:41 - reward: -2.2559\n",
      "episode =  416\n",
      " 3399/10000 [=========>....................] - ETA: 1:35 - reward: -2.2295\n",
      "episode =  417\n",
      " 3595/10000 [=========>....................] - ETA: 1:30 - reward: -2.1743\n",
      "episode =  418\n",
      " 3799/10000 [==========>...................] - ETA: 1:25 - reward: -2.1224\n",
      "episode =  419\n",
      " 3998/10000 [==========>...................] - ETA: 1:21 - reward: -2.2046\n",
      "episode =  420\n",
      " 4195/10000 [===========>..................] - ETA: 1:17 - reward: -2.1303\n",
      "episode =  421\n",
      " 4399/10000 [============>.................] - ETA: 1:13 - reward: -2.1134\n",
      "episode =  422\n",
      " 4599/10000 [============>.................] - ETA: 1:09 - reward: -2.0729\n",
      "episode =  423\n",
      " 4796/10000 [=============>................] - ETA: 1:05 - reward: -2.0884\n",
      "episode =  424\n",
      " 4998/10000 [=============>................] - ETA: 1:02 - reward: -2.0281\n",
      "episode =  425\n",
      " 5195/10000 [==============>...............] - ETA: 58s - reward: -2.0896\n",
      "episode =  426\n",
      " 5399/10000 [===============>..............] - ETA: 55s - reward: -2.1474\n",
      "episode =  427\n",
      " 5599/10000 [===============>..............] - ETA: 52s - reward: -2.0708\n",
      "episode =  428\n",
      " 5797/10000 [================>.............] - ETA: 49s - reward: -2.0206\n",
      "episode =  429\n",
      " 5995/10000 [================>.............] - ETA: 46s - reward: -2.1514\n",
      "episode =  430\n",
      " 6199/10000 [=================>............] - ETA: 43s - reward: -2.1095\n",
      "episode =  431\n",
      " 6398/10000 [==================>...........] - ETA: 41s - reward: -2.0995\n",
      "episode =  432\n",
      " 6597/10000 [==================>...........] - ETA: 38s - reward: -2.0548\n",
      "episode =  433\n",
      " 6799/10000 [===================>..........] - ETA: 35s - reward: -2.1828\n",
      "episode =  434\n",
      " 6997/10000 [===================>..........] - ETA: 33s - reward: -2.1573\n",
      "episode =  435\n",
      " 7195/10000 [====================>.........] - ETA: 30s - reward: -2.2614\n",
      "episode =  436\n",
      " 7399/10000 [=====================>........] - ETA: 28s - reward: -2.3742\n",
      "episode =  437\n",
      " 7598/10000 [=====================>........] - ETA: 26s - reward: -2.3837\n",
      "episode =  438\n",
      " 7799/10000 [======================>.......] - ETA: 24s - reward: -2.4781\n",
      "episode =  439\n",
      " 8000/10000 [=======================>......] - ETA: 22s - reward: -2.4163\n",
      "episode =  440\n",
      " 8200/10000 [=======================>......] - ETA: 20s - reward: -2.3726\n",
      "episode =  441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8400/10000 [========================>.....] - ETA: 18s - reward: -2.4748\n",
      "episode =  442\n",
      " 8600/10000 [========================>.....] - ETA: 16s - reward: -2.5736\n",
      "episode =  443\n",
      " 8800/10000 [=========================>....] - ETA: 14s - reward: -2.5573\n",
      "episode =  444\n",
      " 8997/10000 [=========================>....] - ETA: 11s - reward: -2.6415\n",
      "episode =  445\n",
      " 9200/10000 [==========================>...] - ETA: 9s - reward: -2.6144\n",
      "episode =  446\n",
      " 9399/10000 [===========================>..] - ETA: 7s - reward: -2.6546\n",
      "episode =  447\n",
      " 9600/10000 [===========================>..] - ETA: 4s - reward: -2.7393\n",
      "episode =  448\n",
      " 9799/10000 [============================>.] - ETA: 2s - reward: -2.8221\n",
      "episode =  449\n",
      "10000/10000 [==============================] - 123s 12ms/step - reward: -2.8999\n",
      "\n",
      "episode =  450\n",
      "50 episodes - episode_reward: -579.976 [-1372.586, -0.262] - loss: 10.272 - mean_absolute_error: 1.873 - mean_q: -47.096\n",
      "\n",
      "Interval 10 (90000 steps performed)\n",
      "  199/10000 [..............................] - ETA: 2:42 - reward: -5.2575\n",
      "episode =  451\n",
      "  399/10000 [>.............................] - ETA: 2:39 - reward: -5.6174\n",
      "episode =  452\n",
      "  600/10000 [>.............................] - ETA: 2:36 - reward: -5.8883\n",
      "episode =  453\n",
      "  797/10000 [=>............................] - ETA: 2:33 - reward: -6.1116\n",
      "episode =  454\n",
      "  998/10000 [=>............................] - ETA: 2:29 - reward: -6.2067\n",
      "episode =  455\n",
      " 1197/10000 [==>...........................] - ETA: 2:26 - reward: -6.3141\n",
      "episode =  456\n",
      " 1398/10000 [===>..........................] - ETA: 2:23 - reward: -6.3699\n",
      "episode =  457\n",
      " 1598/10000 [===>..........................] - ETA: 2:19 - reward: -6.2246\n",
      "episode =  458\n",
      " 1800/10000 [====>.........................] - ETA: 2:16 - reward: -6.2210\n",
      "episode =  459\n",
      " 2000/10000 [=====>........................] - ETA: 2:13 - reward: -6.0716\n",
      "episode =  460\n",
      " 2197/10000 [=====>........................] - ETA: 2:10 - reward: -5.7543\n",
      "episode =  461\n",
      " 2400/10000 [======>.......................] - ETA: 2:06 - reward: -5.8485\n",
      "episode =  462\n",
      " 2599/10000 [======>.......................] - ETA: 2:03 - reward: -5.8575\n",
      "episode =  463\n",
      " 2797/10000 [=======>......................] - ETA: 2:00 - reward: -5.5707\n",
      "episode =  464\n",
      " 2999/10000 [=======>......................] - ETA: 1:56 - reward: -5.2373\n",
      "episode =  465\n",
      " 3198/10000 [========>.....................] - ETA: 1:53 - reward: -5.0583\n",
      "episode =  466\n",
      " 3400/10000 [=========>....................] - ETA: 1:49 - reward: -4.7934\n",
      "episode =  467\n",
      " 3599/10000 [=========>....................] - ETA: 1:46 - reward: -4.6636\n",
      "episode =  468\n",
      " 3800/10000 [==========>...................] - ETA: 1:43 - reward: -4.7656\n",
      "episode =  469\n",
      " 3999/10000 [==========>...................] - ETA: 1:40 - reward: -4.5895\n",
      "episode =  470\n",
      " 4199/10000 [===========>..................] - ETA: 1:36 - reward: -4.6889\n",
      "episode =  471\n",
      " 4400/10000 [============>.................] - ETA: 1:33 - reward: -4.5308\n",
      "episode =  472\n",
      " 4599/10000 [============>.................] - ETA: 1:30 - reward: -4.6313\n",
      "episode =  473\n",
      " 4799/10000 [=============>................] - ETA: 1:26 - reward: -4.7243\n",
      "episode =  474\n",
      " 4998/10000 [=============>................] - ETA: 1:23 - reward: -4.6395\n",
      "episode =  475\n",
      " 5199/10000 [==============>...............] - ETA: 1:20 - reward: -4.5523\n",
      "episode =  476\n",
      " 5399/10000 [===============>..............] - ETA: 1:16 - reward: -4.6224\n",
      "episode =  477\n",
      " 5599/10000 [===============>..............] - ETA: 1:13 - reward: -4.6228\n",
      "episode =  478\n",
      " 5800/10000 [================>.............] - ETA: 1:10 - reward: -4.6667\n",
      "episode =  479\n",
      " 5999/10000 [================>.............] - ETA: 1:06 - reward: -4.5714\n",
      "episode =  480\n",
      " 6199/10000 [=================>............] - ETA: 1:03 - reward: -4.4802\n",
      "episode =  481\n",
      " 6400/10000 [==================>...........] - ETA: 1:00 - reward: -4.3587\n",
      "episode =  482\n",
      " 6598/10000 [==================>...........] - ETA: 56s - reward: -4.2651\n",
      "episode =  483\n",
      " 6798/10000 [===================>..........] - ETA: 53s - reward: -4.1746\n",
      "episode =  484\n",
      " 6998/10000 [===================>..........] - ETA: 50s - reward: -4.0724\n",
      "episode =  485\n",
      " 7199/10000 [====================>.........] - ETA: 46s - reward: -4.0104\n",
      "episode =  486\n",
      " 7399/10000 [=====================>........] - ETA: 43s - reward: -3.9345\n",
      "episode =  487\n",
      " 7600/10000 [=====================>........] - ETA: 40s - reward: -3.8621\n",
      "episode =  488\n",
      " 7798/10000 [======================>.......] - ETA: 36s - reward: -3.8277\n",
      "episode =  489\n",
      " 7999/10000 [======================>.......] - ETA: 33s - reward: -3.7471\n",
      "episode =  490\n",
      " 8199/10000 [=======================>......] - ETA: 30s - reward: -3.8142\n",
      "episode =  491\n",
      " 8398/10000 [========================>.....] - ETA: 26s - reward: -3.9026\n",
      "episode =  492\n",
      " 8600/10000 [========================>.....] - ETA: 23s - reward: -3.8684\n",
      "episode =  493\n",
      " 8798/10000 [=========================>....] - ETA: 20s - reward: -3.8538\n",
      "episode =  494\n",
      " 9000/10000 [==========================>...] - ETA: 16s - reward: -3.7674\n",
      "episode =  495\n",
      " 9199/10000 [==========================>...] - ETA: 13s - reward: -3.6991\n",
      "episode =  496\n",
      " 9399/10000 [===========================>..] - ETA: 10s - reward: -3.6986\n",
      "episode =  497\n",
      " 9598/10000 [===========================>..] - ETA: 6s - reward: -3.6349\n",
      "episode =  498\n",
      " 9797/10000 [============================>.] - ETA: 3s - reward: -3.6094\n",
      "episode =  499\n",
      "10000/10000 [==============================] - 167s 17ms/step - reward: -3.5600\n",
      "done, took 1607.987 seconds\n",
      "Finish Learning. We start test phase.\n",
      "Testing for 5 episodes ...\n",
      "Episode 1: reward: -360.103, steps: 200\n",
      "Episode 2: reward: -239.131, steps: 200\n",
      "Episode 3: reward: -125.400, steps: 200\n",
      "Episode 4: reward: -125.434, steps: 200\n",
      "Episode 5: reward: -126.036, steps: 200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x137c87400>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = agent((3,), env.observation_space.shape)\n",
    "print(env.action_space.shape, env.observation_space.shape)\n",
    "agent.compile(Adam(lr=0.001, clipnorm=1.), metrics=[\"mae\"])\n",
    "agent.fit(env, nb_steps=100000, visualize=True, verbose=1, nb_max_episode_steps=200)\n",
    "print('Finish Learning. We start test phase.')\n",
    "agent.test(env, nb_episodes=5, visualize=True, nb_max_episode_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3, 4)\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2]).shape\n",
    "b = np.array([1,2,3]).shape\n",
    "c = np.array([1,2,3,4]).shape\n",
    "print(a + b + c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1, 2)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-82f33ada368c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m]\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m]\u001b[0m \u001b[0;34m]\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "a = np.array([ [ [ 1,2 ] ], [ [ 2,1 ] ] ])\n",
    "print(a.shape)\n",
    "print(a[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array(n):\n",
    "    a = []\n",
    "    for i in range(n):\n",
    "        a.append([1,2])\n",
    "    return a\n",
    "\n",
    "print(array(3))\n",
    "print(array(3)[0])\n",
    "print(array[0](3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2],[3,4],[5,6]])\n",
    "b = np.zeros((3,1))\n",
    "for i in range(a.shape[0]):\n",
    "    b[i] = a[i][0]\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[[1,2]],[[3,2]]])\n",
    "print(a)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1\n",
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic net のビルド時に_feed_input_shape が変わるのでは。 a_shape = (3,)にすれば よいい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
