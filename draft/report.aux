\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}はじめに}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}方策勾配を用いた強化学習}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}強化学習の基礎知識}{1}}
\newlabel{purpose_of_rl}{{1}{1}}
\newlabel{value_function}{{2}{1}}
\newlabel{Q_func}{{4}{1}}
\citation{DQN}
\citation{DPG}
\citation{DDPG}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}方策反復法}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}状態空間, 行動空間の特性に合わせたアルゴリズム}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}方策勾配による方策関数のパラメータの更新}{2}}
\newlabel{true_pg}{{5}{2}}
\newlabel{d_dis}{{6}{2}}
\newlabel{critic_loss}{{8}{2}}
\newlabel{sample_approximation_for_pg}{{10}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {3}最適セルフトリガー制御問題に対する強化学習}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}セルフトリガー制御}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces 制御系}}{3}}
\newlabel{image}{{1}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}最適セルフトリガー制御}{3}}
\newlabel{optimal_policy}{{11}{3}}
\newlabel{value}{{13}{3}}
\newlabel{reward}{{14}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {4}数値実験による課題点の抽出}{4}}
\newlabel{pendulum}{{15}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}初期方策}{4}}
\newlabel{pi_init}{{16}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}学習によって得られた方策}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces $\pi _{\rm  {RL}}$による制御ログ(角度(rad)と通信間隔(s))}}{4}}
\newlabel{self_trigger_log}{{2}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}学習の様子}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces 原点で何も入力を加えない時のcriticと$\tau $のグラフ}}{5}}
\newlabel{tau_gradient_origin}{{3}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces DDPGで得られたcriticによる価値関数$V^{\pi }$の近似}}{5}}
\newlabel{critic_approximation}{{4}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {5}criticからリアプノフ関数へ}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces 教師あり学習で追加学習したcriticによる価値関数$V^{\pi }$の近似}}{6}}
\newlabel{supervised_critic}{{5}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}補足1: 強化学習で得られた$V^{\pi }_{c}$が凸関数のような形になる理由}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces replay bufferの状態に関する密度}}{6}}
\newlabel{replay_buffer_density}{{6}{6}}
\bibcite{ECBF}{1}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}補足2: criticの近似精度が低いにもかかわらず方策が改善できる理由}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces 原点における$Q$関数の入力(トルク, 通信間隔)による変化}}{7}}
\newlabel{a_gradient}{{7}{7}}
