{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/.pyenv/versions/3.6.6/lib/python3.6/site-packages/pandas/compat/__init__.py:84: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import concatenate, Dense, Input, Flatten\n",
    "from keras.optimizers import Adam\n",
    "import gym\n",
    "from rl.agents import DDPGAgent\n",
    "from rl.memory import SequentialMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Space: Box(1,)\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# GymのPendulum環境を作成\n",
    "env = gym.make(\"Pendulum-v0\")\n",
    "\n",
    "# 取りうる”打ち手”のアクション数と値の定義\n",
    "nb_actions = 2\n",
    "ACT_ID_TO_VALUE = {0: [-1], 1: [+1]}\n",
    "\n",
    "print(\"Action Space: %s\" % env.action_space)\n",
    "#action  dim = 1\n",
    "#critic dim = 3 with ??\n",
    "print( env.observation_space.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actor_net(a_shape, s_shape):\n",
    "    action_input = Input(shape=(1,)+s_shape)\n",
    "    x = Flatten()(action_input)\n",
    "    x = Dense(16, activation=\"relu\")(x)\n",
    "    x = Dense(16, activation=\"relu\")(x)\n",
    "    x = Dense(a_shape[0], activation=\"linear\")(x)\n",
    "    actor = Model(inputs=action_input, outputs=x)\n",
    "    return actor\n",
    "\n",
    "def critic_net(a_shape, s_shape):\n",
    "    action_input = Input(a_shape)\n",
    "    observation_input = Input(shape=(1,)+s_shape)\n",
    "    flattened_observation = Flatten()(observation_input)\n",
    "    x = concatenate([action_input, flattened_observation])\n",
    "    x = Dense(32, activation=\"relu\")(x)\n",
    "    x = Dense(32, activation=\"relu\")(x)\n",
    "    x = Dense(1, activation=\"linear\")(x)\n",
    "    critic = Model(inputs=[action_input, observation_input], outputs=x)\n",
    "    return (critic, action_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent(a_shape, s_shape):\n",
    "    actor = actor_net(a_shape, s_shape)\n",
    "    critic,  critic_action_input = critic_net(a_shape, s_shape)\n",
    "    memory = SequentialMemory(limit = 50000, window_length = 1)\n",
    "    agent = DDPGAgent(\n",
    "        a_shape[0],\n",
    "        actor,\n",
    "        critic,\n",
    "        critic_action_input,\n",
    "        memory,\n",
    "        target_model_update=.01\n",
    "    )\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1010 19:57:27.034594 140735584400256 deprecation_wrapper.py:119] From /Users/admin/.pyenv/versions/3.6.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1010 19:57:27.054357 140735584400256 deprecation_wrapper.py:119] From /Users/admin/.pyenv/versions/3.6.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1010 19:57:27.071994 140735584400256 deprecation_wrapper.py:119] From /Users/admin/.pyenv/versions/3.6.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4158: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1010 19:57:27.194554 140735584400256 deprecation_wrapper.py:119] From /Users/admin/.pyenv/versions/3.6.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W1010 19:57:27.195549 140735584400256 deprecation_wrapper.py:119] From /Users/admin/.pyenv/versions/3.6.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,) (3,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1010 19:57:27.482129 140735584400256 deprecation_wrapper.py:119] From /Users/admin/.pyenv/versions/3.6.6/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.optimizers.Adam object at 0x12b186d68>\n",
      "Training for 50000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "10000/10000 [==============================] - 50s 5ms/step - reward: -4.9738\n",
      "50 episodes - episode_reward: -994.765 [-1687.718, -1.917] - loss: 69.893 - mean_squared_error: 139.786 - mean_q: -150.064\n",
      "\n",
      "Interval 2 (10000 steps performed)\n",
      "10000/10000 [==============================] - 46s 5ms/step - reward: -1.2919\n",
      "50 episodes - episode_reward: -258.381 [-1501.185, -0.793] - loss: 61.988 - mean_squared_error: 123.975 - mean_q: -142.281\n",
      "\n",
      "Interval 3 (20000 steps performed)\n",
      "10000/10000 [==============================] - 48s 5ms/step - reward: -0.8673\n",
      "50 episodes - episode_reward: -173.464 [-400.803, -1.116] - loss: 19.124 - mean_squared_error: 38.249 - mean_q: -47.912\n",
      "\n",
      "Interval 4 (30000 steps performed)\n",
      "10000/10000 [==============================] - 50s 5ms/step - reward: -0.8571\n",
      "50 episodes - episode_reward: -171.420 [-438.786, -1.266] - loss: 18.267 - mean_squared_error: 36.534 - mean_q: 28.752\n",
      "\n",
      "Interval 5 (40000 steps performed)\n",
      "10000/10000 [==============================] - 52s 5ms/step - reward: -4.4338\n",
      "done, took 246.138 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12b857f28>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = agent(env.action_space.shape, env.observation_space.shape)\n",
    "print(env.action_space.shape, env.observation_space.shape)\n",
    "agent.compile(Adam(lr=0.001, clipnorm=1., decay = 0.001), metrics=[\"mse\"])\n",
    "agent.fit(env, nb_steps=50000, visualize=0, verbose=1, nb_max_episode_steps=200)\n",
    "#agent.test(env, nb_episodes=5, visualize=0, nb_max_episode_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 5 episodes ...\n",
      "Episode 1: reward: -745.911, steps: 200\n",
      "Episode 2: reward: -734.510, steps: 200\n",
      "Episode 3: reward: -124.128, steps: 200\n",
      "Episode 4: reward: -648.875, steps: 200\n",
      "Episode 5: reward: -765.605, steps: 200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12faac908>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.test(env, nb_episodes=5, visualize=1, nb_max_episode_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 30000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "10000/10000 [==============================] - 49s 5ms/step - reward: -7.4902\n",
      "50 episodes - episode_reward: -1498.042 [-1657.866, -945.195] - loss: 7465498288767733071872.000 - mean_squared_error: 14930996577535466143744.000 - mean_q: 9759891516.987\n",
      "\n",
      "Interval 2 (10000 steps performed)\n",
      "10000/10000 [==============================] - 49s 5ms/step - reward: -6.9553\n",
      "50 episodes - episode_reward: -1391.066 [-1657.149, -858.739] - loss: 389024682807153416732672.000 - mean_squared_error: 778049365614306833465344.000 - mean_q: 106456883200.000\n",
      "\n",
      "Interval 3 (20000 steps performed)\n",
      " 3344/10000 [=========>....................] - ETA: 40s - reward: -7.1895done, took 118.580 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12b027518>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.fit(env, nb_steps=30000, visualize=0, verbose=1, nb_max_episode_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
