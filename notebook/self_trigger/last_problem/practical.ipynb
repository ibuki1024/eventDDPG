{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../../module/')\n",
    "\n",
    "from keras2.models import Model\n",
    "from keras2.layers import concatenate, Dense, Input, Flatten\n",
    "from keras2.optimizers import Adam, Optimizer\n",
    "import keras2.backend as K\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "import itertools\n",
    "from util import *\n",
    "import gym2\n",
    "from rl2.agents import selfDDPGAgent, selfDDPGAgent2, selfDDPGAgent3\n",
    "from rl2.memory import SequentialMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym2.make('Pendulum-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def critic_net(a_shape , s_shape):\n",
    "    action_input = Input(a_shape)\n",
    "    observation_input = Input(shape=(1,)+s_shape)\n",
    "    flattened_observation = Flatten()(observation_input)\n",
    "    x = concatenate([action_input, flattened_observation])\n",
    "    x = Dense(16, activation=\"relu\")(x)\n",
    "    x = Dense(16, activation=\"relu\")(x)\n",
    "    x = Dense(1, activation=\"linear\")(x)\n",
    "    critic = Model(inputs=[action_input, observation_input], outputs=x)\n",
    "    return (critic, action_input)\n",
    "\n",
    "def value_net(s_shape):\n",
    "    state_input = Input((1,)+s_shape)\n",
    "    x = Flatten()(state_input)\n",
    "    \n",
    "    x = Dense(16, activation='relu')(x)\n",
    "    x = Dense(16, activation='relu')(x)\n",
    "    x = Dense(1, activation=\"linear\")(x)\n",
    "    value = Model(inputs=state_input, output=x)\n",
    "    return value\n",
    "\n",
    "def branch_actor(a_shape, s_shape):\n",
    "    action_input = Input(shape=(1,)+s_shape)\n",
    "    x = Flatten()(action_input) # 実質的なinput layer\n",
    "    \n",
    "    x1 = Dense(8, activation=\"relu\")(x)\n",
    "    x1 = Dense(8, activation=\"relu\")(x1)\n",
    "    x1 = Dense(1, activation=\"multiple_tanh\")(x1) # action signal\n",
    "    \n",
    "    x2 = Dense(8, activation=\"relu\")(x)\n",
    "    x2 = Dense(8, activation=\"relu\")(x2)\n",
    "    x2 = Dense(1, activation=\"tau_output_large\")(x2) # tau\n",
    "    \n",
    "    output = concatenate([x1, x2])\n",
    "    actor = Model(inputs=action_input, outputs=output)\n",
    "    return actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1\n",
    "beta = .5\n",
    "\n",
    "dummy_optimizer = Optimizer()\n",
    "\n",
    "def gradient_old(state, next_state, actor, critic):\n",
    "    params = actor.trainable_weights\n",
    "    \n",
    "    # q_func gradient tensor\n",
    "    state_input = tf.placeholder(tf.float32, shape=(None, 1, 2))\n",
    "    actor_output = actor(state_input)\n",
    "    combined_input_tensor = [actor_output, state_input]\n",
    "    critic_output_tensor = critic(combined_input_tensor)\n",
    "    loss = -K.mean(critic_output_tensor)\n",
    "    gradient_for_q = dummy_optimizer.get_gradients(loss, params)\n",
    "    \n",
    "    # discount factor gradient tensor\n",
    "    discount = - tf.exp(- alpha * actor_output[0][1])\n",
    "    gradient_for_d = dummy_optimizer.get_gradients(discount, params)\n",
    "    next_state_input = tf.placeholder(tf.float32, shape=(None, 1, 2))\n",
    "    next_action = actor(next_state_input)\n",
    "    next_value = critic([next_action, next_state_input])[0][0]\n",
    "    gradient_for_d = [next_value * g for g in gradient_for_d]\n",
    "    \n",
    "    # gradient\n",
    "    gradient_tensor = [K.add(gq, gd) for gq, gd in zip(gradient_for_q, gradient_for_d)]\n",
    "    \n",
    "    # calc\n",
    "    grad_calc_func = K.function([state_input, next_state_input], gradient_tensor)\n",
    "    q_g = grad_calc_func([[state], [next_state]]) # ここに0.5sくらいかかる\n",
    "\n",
    "    return q_g\n",
    "\n",
    "\n",
    "def gradient_for_one_data(state, next_state, actor, critic):\n",
    "    params = actor.trainable_weights  \n",
    "    # q_func gradient tensor\n",
    "    state_input = tf.constant([[state.tolist()]], tf.float32)\n",
    "    actor_output = actor(state_input)\n",
    "    combined_input_tensor = [actor_output, state_input]\n",
    "    critic_output_tensor = critic(combined_input_tensor)\n",
    "    loss = -K.mean(critic_output_tensor)\n",
    "    gradient_for_q = dummy_optimizer.get_gradients(loss, params) # 300msくらいかかっちゃう\n",
    "    \n",
    "    # discount factor gradient tensor\n",
    "    discount = - tf.exp(- alpha * actor_output[0][1])\n",
    "    gradient_for_d = dummy_optimizer.get_gradients(discount, params)\n",
    "    next_state_input = tf.constant([[next_state.tolist()]], tf.float32)\n",
    "    next_action = actor(next_state_input)\n",
    "    next_value = critic([next_action, next_state_input])[0][0]\n",
    "    gradient_for_d = [next_value * g for g in gradient_for_d]\n",
    "    \n",
    "    gradient_for_one_state = [K.add(gq, gd) for gq, gd in zip(gradient_for_q, gradient_for_d)]\n",
    "    \n",
    "    return gradient_for_one_state\n",
    "\n",
    "def gradient(states, next_states, actor, critic):\n",
    "    batch_size = len(states)\n",
    "    for i in range(batch_size):\n",
    "        state, next_state = states[i], next_states[i]\n",
    "        g_tensor = gradient_for_one_data(state, next_state, actor, critic)\n",
    "        if i == 0:\n",
    "            out = [tf.constant(0.)] * len(g_tensor)\n",
    "            out = [K.add(o, g) / batch_size for o, g in zip(out, g_tensor)]\n",
    "        else:\n",
    "            out = [K.add(o, g) / batch_size for o, g in zip(out, g_tensor)]\n",
    "    func = K.function([], out)\n",
    "    gg = func([[]])\n",
    "    return gg\n",
    "\n",
    "# Adam クラス\n",
    "def learning_rate_arr(actor, size=210, u_lr=.00001, tau_lr=.0001):\n",
    "    grad_idx = 0\n",
    "    i, j = 0, 0\n",
    "    lrs = np.zeros((size,))\n",
    "    for layer in actor.layers:\n",
    "        if len(layer.get_weights())==0:\n",
    "            continue\n",
    "        else:\n",
    "            w, b = layer.get_weights()\n",
    "            grad_idx += len(w.ravel()) + len(b.ravel())\n",
    "            if j % 2 == 0: # u\n",
    "                lrs[i:grad_idx] = u_lr\n",
    "            else: # tau\n",
    "                lrs[i:grad_idx] = tau_lr\n",
    "            i = grad_idx\n",
    "            j += 1\n",
    "    return lrs\n",
    "\n",
    "    \n",
    "def flatten_gradient(gradient):\n",
    "    params = []\n",
    "    for i in range(len(gradient)//2):\n",
    "        w, b = gradient[2*i], gradient[2*i+1]\n",
    "        layer_params = np.hstack((w.ravel(), b.ravel()))\n",
    "        params = np.hstack((params, layer_params))\n",
    "    params = np.array(params).ravel()\n",
    "    return params\n",
    "\n",
    "\n",
    "def get_nn_params(actor):\n",
    "    params = []\n",
    "    for layer in actor.layers:\n",
    "        if len(layer.get_weights())==0:\n",
    "            continue\n",
    "        else:\n",
    "            w, b = layer.get_weights()\n",
    "            layer_params = np.hstack((w.ravel(), b.ravel()))\n",
    "            params = np.hstack((params, layer_params))\n",
    "    params = np.array(params).ravel()\n",
    "    return params\n",
    "\n",
    "def set_nn_params(actor, params):\n",
    "    param_idx = 0\n",
    "    for layer in actor.layers:\n",
    "        if len(layer.get_weights())==0:\n",
    "            continue\n",
    "        else:\n",
    "            w, b = layer.get_weights()\n",
    "            # set w\n",
    "            w_prime = params[param_idx:param_idx+w.ravel().shape[0]].reshape(w.shape)\n",
    "            param_idx += w.ravel().shape[0]\n",
    "\n",
    "            # set b\n",
    "            b_prime = params[param_idx:param_idx+b.ravel().shape[0]].reshape(b.shape)\n",
    "            param_idx += b.ravel().shape[0]\n",
    "\n",
    "            layer.set_weights([w_prime, b_prime])\n",
    "    assert params.shape[0] == param_idx\n",
    "    return actor\n",
    "\n",
    "class Adam_original():\n",
    "    def __init__(self, lrs, beta_1=.9, beta_2=.999, epsilon=1e-6):\n",
    "        self.lrs = lrs # 学習率\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "        self.m = np.zeros(210,) # 前回の勾配\n",
    "        self.v = np.zeros(210,) # 前回の2乗勾配\n",
    "    \n",
    "    def update(self, actor, pg):\n",
    "        # update m\n",
    "        self.m = (self.beta_1 * self.m) + (1. - self.beta_1) * pg\n",
    "        \n",
    "        # update v\n",
    "        self.v = (self.beta_2 * self.v) + (1. - self.beta_2) * pg**2\n",
    "        \n",
    "        # 更新量を決める\n",
    "        ag = self.lrs * self.m / (np.sqrt(self.v) + self.epsilon)\n",
    "        \n",
    "        # 今のパラメータ\n",
    "        ps = get_nn_params(actor)\n",
    "        \n",
    "        # update\n",
    "        ps = ps - ag\n",
    "        \n",
    "        # update\n",
    "        actor = set_nn_params(actor, ps)\n",
    "    \n",
    "        return actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1ステップのインタラクション\n",
    "def interaction(state, u, tau, env, ln=0):\n",
    "    env.reset()\n",
    "    x = np.array(state)\n",
    "    env.set_state(x)\n",
    "    reward = 0\n",
    "    a_agent, tau = u, tau\n",
    "    tau = np.clip(tau, 0.01, 10.)\n",
    "    action_repetition = int(np.ceil(100 * tau))  # minimum natural number which makes `dt` smaller than 0.005\n",
    "    dt = .01\n",
    "    for p in range(action_repetition):\n",
    "        _,r,_,_ = env.step(np.array([a_agent]), dt, tau, ln)\n",
    "        r *= np.exp(- alpha * p * dt)\n",
    "        reward += r\n",
    "    reward *= dt\n",
    "    reward -= beta\n",
    "    state1 = env.state\n",
    "    return reward, state1\n",
    "\n",
    "\n",
    "# 学習データ\n",
    "def train_data(actor, noise=False):\n",
    "    memory = []\n",
    "    S1 = np.linspace(-7, 7, 20)\n",
    "    S2 = np.linspace(-7, 7, 20)\n",
    "    S1, S2 = np.meshgrid(S1, S2)\n",
    "    S1, S2 = S1.flatten(), S2.flatten()\n",
    "    \n",
    "    ln = 1 if noise else 0\n",
    "    n = 5 if noise else 1\n",
    "    \n",
    "    for _ in range(n):\n",
    "        for i, x in enumerate(zip(S1, S2)):\n",
    "            state0 = np.array(x)\n",
    "            noise = np.array([np.random.randn() / 10., np.random.randn() / 100.])\n",
    "            a_agent, tau = actor.predict_on_batch(state0.reshape((1,1,)+state0.shape))[0] + ln*noise\n",
    "            reward, state1 = interaction(state0, a_agent, tau, env, ln=0.1)\n",
    "            memory.append([state0, np.array([a_agent, tau]), reward, state1])\n",
    "    memory = np.array(memory)\n",
    "    return memory\n",
    "\n",
    "# Q関数の学習\n",
    "def td_learning(memory, actor, critic, target_actor, target_critic, batch_size=32, epoch=5000):\n",
    "    # TODO: loss小さい=関数として正しい　をチェックする\n",
    "    assert critic.compile, 'compile critic before use this function'\n",
    "    # critic learning\n",
    "    arr = np.array(range(memory.shape[0]))\n",
    "    losses = []\n",
    "    for _ in range(epoch):\n",
    "        # make mini_batch\n",
    "        mem = memory[np.random.choice(arr, batch_size, replace=False)]\n",
    "        state0_batch = []\n",
    "        action_batch = []\n",
    "        reward_batch = []\n",
    "        state1_batch = []\n",
    "        for m in mem:\n",
    "            state0_batch.append([m[0]])\n",
    "            action_batch.append(m[1])\n",
    "            reward_batch.append([m[2]])\n",
    "            state1_batch.append([m[3]])\n",
    "        state0_batch, action_batch, reward_batch, state1_batch = \\\n",
    "        np.array(state0_batch), np.array(action_batch), np.array(reward_batch), np.array(state1_batch)\n",
    "\n",
    "        # TD error\n",
    "        next_action = target_actor.predict_on_batch(state1_batch)\n",
    "        state1_batch_with_action = [next_action, state1_batch]\n",
    "        target = target_critic.predict_on_batch(state1_batch_with_action)\n",
    "        discount = np.exp(- alpha * action_batch[:,1].reshape(batch_size, 1))\n",
    "        r_second = np.multiply(discount, target)\n",
    "        r = reward_batch + r_second\n",
    "\n",
    "        # learn\n",
    "        critic_input_batch = [action_batch, state0_batch]\n",
    "        loss = critic.train_on_batch(critic_input_batch, r)\n",
    "        \n",
    "        losses.append(loss)\n",
    "        \n",
    "    return critic, losses\n",
    "\n",
    "# 勾配の計算\n",
    "def policy_gradient(actor, critic, init_state = np.array([3,3])):\n",
    "    # 初期状態からのシミュレーション\n",
    "    x = init_state\n",
    "    episode_time = 0\n",
    "    log = []\n",
    "    while True:\n",
    "        a_agent, tau = actor.predict_on_batch(x.reshape(1,1,2))[0]\n",
    "        log.append([x, episode_time])\n",
    "        reward, x = interaction(x, a_agent, tau, env, ln=0.1)\n",
    "        episode_time += tau\n",
    "        if episode_time >= 10.:\n",
    "            log.append([x, episode_time])\n",
    "            break\n",
    "    \n",
    "    # Q 関数の勾配を計算する\n",
    "    tmp = []\n",
    "    for i in range(len(log) - 1):\n",
    "        tmp.append([log[i][0], log[i][1], log[i+1][0]])\n",
    "    tmp = np.array(tmp)\n",
    "    states, ts, next_states = tmp[:,0], tmp[:,1], tmp[:,2]\n",
    "    pg = gradient(states, ts, next_states, actor, critic)\n",
    "    pg = flatten_gradient(pg)\n",
    "    return pg\n",
    "\n",
    "def update_target_model(model, target_model, l=0.01):\n",
    "    p = l * get_nn_params(model) + (1 - l) * get_nn_params(target_model)\n",
    "    target_model = set_nn_params(target_model, p)\n",
    "    return target_model\n",
    "\n",
    "# 評価\n",
    "def evaluation(actor, init_state = np.array([3,3])):\n",
    "    x = init_state\n",
    "    episode_time = 0\n",
    "    episode_reward = 0\n",
    "    log = []\n",
    "    while True:\n",
    "        a_agent, tau = actor.predict_on_batch(x.reshape(1,1,2))[0]\n",
    "        log.append([x, episode_time])\n",
    "        reward, x = interaction(x, a_agent, tau, env, ln=0.)\n",
    "        episode_reward += np.exp(- alpha * episode_time) * reward\n",
    "        episode_time += tau\n",
    "        if episode_time >= 10.:\n",
    "            log.append([x, episode_time])\n",
    "            break\n",
    "    return episode_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replay buffer の実装\n",
    "class replay_buffer():\n",
    "    def __init__(self, n_limits=30000):\n",
    "        self.n_limits = n_limits\n",
    "        self.memory = []\n",
    "        \n",
    "    def store(self, experience):\n",
    "        # (s, a, r, s', e^-at)\n",
    "        assert len(experience) == 5, 'shape error'\n",
    "        self.memory.append(experience)\n",
    "        if len(self.memory) >= self.n_limits:\n",
    "            del self.memory[0]\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        batch = []\n",
    "        idx_log = []\n",
    "        while len(batch) < batch_size:\n",
    "            idx = np.random.choice(range(len(self.memory)))\n",
    "            candidate = self.memory[idx]\n",
    "            if idx in idx_log:\n",
    "                continue\n",
    "            if np.random.rand() < candidate[-1]:\n",
    "                idx_log.append(idx)\n",
    "                batch.append(candidate)\n",
    "        assert len(batch) == batch_size, ''\n",
    "        return np.array(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor = branch_actor((2,),(2,))\n",
    "critic = critic_net((2,),(2,))[0]\n",
    "target_actor = branch_actor((2,),(2,))\n",
    "target_critic = critic_net((2,),(2,))[0]\n",
    "critic.compile(Adam(lr=0.001, clipnorm=1.), loss='mean_squared_error')\n",
    "target_critic.compile(Adam(lr=0.001, clipnorm=1.), loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor.load_weights('../saved_agent/learned_self_clipped_actor.h5')\n",
    "critic.load_weights('../saved_agent/learned_self_clipped_critic_l.h5')\n",
    "target_actor.load_weights('../saved_agent/learned_self_clipped_actor.h5')\n",
    "target_critic.load_weights('../saved_agent/learned_self_clipped_critic_l.h5')\n",
    "lrs = learning_rate_arr(actor, size=210, u_lr=.0001, tau_lr=.001)\n",
    "opt = Adam_original(lrs)\n",
    "ev = evaluation(actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value_function for initial policy = -49.25818715854261\n",
      "0-step\n",
      "loss of critic is 105.89337158203125, value_fuction V(s) = -53.738557969690675\n",
      "|g| = 1.159620821149278\n",
      "1-step\n",
      "loss of critic is 97.12177276611328, value_fuction V(s) = -52.734632854479216\n",
      "|g| = 3.6596142668147476\n",
      "2-step\n",
      "loss of critic is 93.79509735107422, value_fuction V(s) = -44.660425828144646\n",
      "|g| = 0.9417830892065379\n",
      "3-step\n",
      "loss of critic is 45.628700256347656, value_fuction V(s) = -51.50991305189328\n",
      "|g| = 2.8087261787034836\n",
      "4-step\n",
      "loss of critic is 45.868412017822266, value_fuction V(s) = -41.181960525492705\n",
      "|g| = 8.097379391315627\n",
      "5-step\n",
      "loss of critic is 55.44102096557617, value_fuction V(s) = -46.957882604062334\n",
      "|g| = 8.468886734173058\n",
      "6-step\n",
      "loss of critic is 48.857643127441406, value_fuction V(s) = -41.53364454974754\n",
      "|g| = 1.9136001289552755\n",
      "7-step\n",
      "loss of critic is 45.045249938964844, value_fuction V(s) = -38.393345476513865\n",
      "|g| = 1.2949634722330763\n",
      "8-step\n",
      "loss of critic is 31.601608276367188, value_fuction V(s) = -46.66202424418697\n",
      "|g| = 1.4807291241912257\n",
      "9-step\n",
      "loss of critic is 31.74203109741211, value_fuction V(s) = -50.262385897789876\n",
      "|g| = 0.40074279354291237\n",
      "10-step\n",
      "loss of critic is 23.594127655029297, value_fuction V(s) = -49.69380800797988\n",
      "|g| = 0.4039036841240583\n",
      "11-step\n",
      "loss of critic is 38.51405334472656, value_fuction V(s) = -42.60460512930788\n",
      "|g| = 1.3436817647720052\n",
      "12-step\n",
      "loss of critic is 25.117000579833984, value_fuction V(s) = -40.28721059397158\n",
      "|g| = 3.56664069814283\n",
      "13-step\n",
      "loss of critic is 7.86648416519165, value_fuction V(s) = -50.69565651609715\n",
      "|g| = 1.8901550516073033\n",
      "14-step\n",
      "loss of critic is 27.915199279785156, value_fuction V(s) = -68.11764339589499\n",
      "|g| = 10.11264350599281\n",
      "15-step\n",
      "loss of critic is 16.20212745666504, value_fuction V(s) = -56.504842338691326\n",
      "|g| = 1.5061299295877488\n",
      "16-step\n",
      "loss of critic is 6.568475246429443, value_fuction V(s) = -60.30478287697328\n",
      "|g| = 5.063148715888419\n",
      "17-step\n",
      "loss of critic is 4.224386692047119, value_fuction V(s) = -54.29638335119122\n",
      "|g| = 5.448030907439456\n",
      "18-step\n",
      "loss of critic is 8.10655689239502, value_fuction V(s) = -58.78562673048277\n",
      "|g| = 3.107210414467661\n",
      "19-step\n",
      "loss of critic is 12.73240852355957, value_fuction V(s) = -43.478301120183424\n",
      "|g| = 3.0980468347439487\n",
      "20-step\n",
      "loss of critic is 8.135032653808594, value_fuction V(s) = -46.688013088125665\n",
      "|g| = 8.506911845175566\n",
      "21-step\n",
      "loss of critic is 10.01537799835205, value_fuction V(s) = -54.416157898052944\n",
      "|g| = 3.513178991369189\n",
      "22-step\n",
      "loss of critic is 6.030400276184082, value_fuction V(s) = -58.19227251645597\n",
      "|g| = 10.440619581196245\n",
      "23-step\n",
      "loss of critic is 3.826070785522461, value_fuction V(s) = -53.35673324393421\n",
      "|g| = 4.300366835578103\n",
      "24-step\n",
      "loss of critic is 9.59235954284668, value_fuction V(s) = -55.08570027508044\n",
      "|g| = 2.6712152373806206\n",
      "25-step\n",
      "loss of critic is 8.517086029052734, value_fuction V(s) = -55.75834464381578\n",
      "|g| = 4.0250115629696595\n",
      "26-step\n",
      "loss of critic is 5.869141578674316, value_fuction V(s) = -57.43094013618577\n",
      "|g| = 3.786529846327734\n",
      "27-step\n",
      "loss of critic is 6.34932804107666, value_fuction V(s) = -52.968959547440264\n",
      "|g| = 4.376157955154048\n",
      "28-step\n",
      "loss of critic is 4.768780708312988, value_fuction V(s) = -46.721998919005046\n",
      "|g| = 3.5876701978542638\n",
      "29-step\n",
      "loss of critic is 4.63679313659668, value_fuction V(s) = -43.92564893830688\n",
      "|g| = 1.9498729917424011\n",
      "30-step\n",
      "loss of critic is 3.7965128421783447, value_fuction V(s) = -54.03502889979197\n",
      "|g| = 4.271713896741427\n",
      "31-step\n",
      "loss of critic is 4.198472499847412, value_fuction V(s) = -48.87568839196171\n",
      "|g| = 2.0202412315449645\n",
      "32-step\n",
      "loss of critic is 2.973571300506592, value_fuction V(s) = -45.90444162794755\n",
      "|g| = 3.1800978623340304\n",
      "33-step\n",
      "loss of critic is 5.175652980804443, value_fuction V(s) = -39.60187236837642\n",
      "|g| = 1.4582174632282958\n",
      "34-step\n",
      "loss of critic is 5.643129825592041, value_fuction V(s) = -61.467972399021015\n",
      "|g| = 1.2743942098221681\n",
      "35-step\n",
      "loss of critic is 5.415550708770752, value_fuction V(s) = -53.92437436044895\n",
      "|g| = 8.709772297826477\n",
      "36-step\n",
      "loss of critic is 7.715963363647461, value_fuction V(s) = -52.30372339065168\n",
      "|g| = 6.624529072477834\n",
      "37-step\n",
      "loss of critic is 2.040466785430908, value_fuction V(s) = -49.16877084631526\n",
      "|g| = 5.311979868347702\n",
      "38-step\n",
      "loss of critic is 2.593437671661377, value_fuction V(s) = -50.91044294699785\n",
      "|g| = 9.002805255850436\n",
      "39-step\n",
      "loss of critic is 5.743471145629883, value_fuction V(s) = -51.55874124796779\n",
      "|g| = 1.515921594775956\n",
      "40-step\n",
      "loss of critic is 1.6853625774383545, value_fuction V(s) = -40.79347375800212\n",
      "|g| = 0.9540957188257603\n",
      "41-step\n",
      "loss of critic is 13.253584861755371, value_fuction V(s) = -46.21197329099354\n",
      "|g| = 4.298332491539424\n",
      "42-step\n",
      "loss of critic is 3.207054376602173, value_fuction V(s) = -59.26913030356492\n",
      "|g| = 4.050413381429431\n",
      "43-step\n",
      "loss of critic is 4.655465602874756, value_fuction V(s) = -59.067799971157086\n",
      "|g| = 0.38411098853253184\n",
      "44-step\n",
      "loss of critic is 4.397022247314453, value_fuction V(s) = -46.87182073394228\n",
      "|g| = 5.353850417343398\n",
      "45-step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-f170dc7d495b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mcritic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtd_learning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcritic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_actor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_critic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mpg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcritic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mactor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpg\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-cbedb51661b8>\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(states, next_states, actor, critic)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mg_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_for_one_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcritic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-cbedb51661b8>\u001b[0m in \u001b[0;36mgradient_for_one_data\u001b[0;34m(state, next_state, actor, critic)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;31m# discount factor gradient tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mdiscount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mactor_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mgradient_for_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdummy_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mnext_state_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mnext_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/studyM2/projects/eventddpg/module/keras2/optimizers.py\u001b[0m in \u001b[0;36mget_gradients\u001b[0;34m(self, loss, params)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             raise ValueError('An operation has `None` for gradient. '\n",
      "\u001b[0;32m~/Documents/studyM2/projects/eventddpg/module/keras2/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(loss, variables)\u001b[0m\n\u001b[1;32m   2765\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mgradients\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2766\u001b[0m     \"\"\"\n\u001b[0;32m-> 2767\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.4/lib/python3.7/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_ys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mgate_gradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maggregation_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         unconnected_gradients)\n\u001b[0m\u001b[1;32m    159\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.4/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[1;32m    615\u001b[0m     \u001b[0mstop_gradient_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop_gradients\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m     reachable_to_ops, pending_count, loop_state = _PendingCount(\n\u001b[0;32m--> 617\u001b[0;31m         to_ops, from_ops, colocate_gradients_with_ops, func_graphs, xs)\n\u001b[0m\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Iterate over the collected ops.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(f'value_function for initial policy = {ev}')\n",
    "\n",
    "s = np.random.uniform(-7,7,2)\n",
    "episode_time = 0\n",
    "time_limit = 10.\n",
    "batch_size = 16\n",
    "buffer = replay_buffer(n_limits=30000)\n",
    "n_warm_up = 1000\n",
    "ev_log = [ev]\n",
    "for i in range(1100):\n",
    "    u, tau = actor.predict_on_batch(s.reshape(1,1,2))[0]\n",
    "    r, s_prime = interaction(s, u, tau, env, ln=0.1)\n",
    "    buffer.store([s, np.array([u, tau]), r, s_prime, np.exp(- alpha * episode_time)])\n",
    "    episode_time += tau\n",
    "    s = s_prime\n",
    "    if episode_time >= time_limit:\n",
    "        s = np.random.uniform(-7,7,2)\n",
    "        episode_time = 0\n",
    "    if i < n_warm_up:\n",
    "        continue\n",
    "    print(f'{i-n_warm_up}-step')\n",
    "    batch = buffer.sample(batch_size)\n",
    "    critic, losses = td_learning(batch[:,:4], actor, critic, target_actor, target_critic, batch_size=batch_size, epoch=1)\n",
    "    pg = flatten_gradient(gradient(batch[:,0], batch[:,3], actor, critic))\n",
    "    actor = opt.update(actor, pg/np.linalg.norm(pg))\n",
    "    ev = evaluation(actor)\n",
    "    ev_log.append(ev)\n",
    "    target_actor = update_target_model(actor, target_actor)\n",
    "    target_critic = update_target_model(critic, target_critic)\n",
    "    print(f'loss of critic is {np.mean(losses)}, value_fuction V(s) = {ev}')\n",
    "    print(f'|g| = {np.linalg.norm(pg)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "# actor.load_weights('../saved_agent/learned_self_linear_ideal0_actor.h5')\n",
    "# actor.load_weights('../saved_agent/learned_self_linear1_extend_actor.h5')\n",
    "initial_state = np.array([3., 3.])\n",
    "env.set_state(initial_state)\n",
    "\n",
    "states = [initial_state]\n",
    "detail_states = [initial_state]\n",
    "\n",
    "time_limit = 10\n",
    "time_log = [0.]\n",
    "taus = []\n",
    "acc_time = 0\n",
    "episode_reward = 0\n",
    "i = 0\n",
    "detail_time_log = [0.]\n",
    "\n",
    "action_log = []\n",
    "\n",
    "\n",
    "while True:\n",
    "    reward = 0\n",
    "    x = env.state\n",
    "    a_agent, tau = actor.predict_on_batch(x.reshape(1,1,2))[0]\n",
    "    taus.append(tau)\n",
    "    tau = np.clip(tau, .01, 10.)\n",
    "    acc_time += tau\n",
    "    time_log.append(acc_time)\n",
    "    dt = 0.01\n",
    "    action_repetition = int(tau * 100)  # minimum natural number which makes `dt` smaller than 0.005\n",
    "    # print(tau, dt, action_repetition)\n",
    "    for p in range(action_repetition):\n",
    "        action_log.append(a_agent)\n",
    "        _,r,_,_ = env.step(np.array([a_agent]), dt, tau, ln=.1)\n",
    "        detail_states.append(env.state)\n",
    "        i += 1\n",
    "        detail_time_log.append(i * dt)\n",
    "    states.append(env.state)\n",
    "    if acc_time > time_limit:\n",
    "        break\n",
    "action_log.append(actor.predict_on_batch(env.state.reshape(1,1,2))[0][0])\n",
    "states = np.array(states)\n",
    "detail_states = np.array(detail_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.subplots_adjust(hspace=0.6)\n",
    "\n",
    "# state\n",
    "plt.subplot(3,1,1)\n",
    "plt.xlabel('control time (s)')\n",
    "plt.ylabel('$angle$')\n",
    "plt.plot(detail_time_log, detail_states[:,0])\n",
    "#plt.scatter(time_log, states[:,0], marker='.')\n",
    "\n",
    "# action\n",
    "plt.subplot(3,1,2)\n",
    "plt.xlabel('control time (s)')\n",
    "plt.ylabel('$u$')\n",
    "plt.plot(detail_time_log, action_log, color='red')\n",
    "\n",
    "# communication\n",
    "indices = []\n",
    "for t in np.round(time_log, decimals=2):\n",
    "    if t in np.round(detail_time_log, decimals=2):\n",
    "        indices.append(np.where(t == np.round(detail_time_log, decimals=2))[0][0])\n",
    "com = np.zeros_like(detail_time_log)\n",
    "com[indices] = 1\n",
    "plt.subplot(3,1,3)\n",
    "plt.xlabel('control time (s)')\n",
    "plt.ylabel('interaction (bool)')\n",
    "plt.plot(detail_time_log, com, color='black')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor.save_weights('../saved_agent/learned_self_proposed0_actor.h5')\n",
    "critic.save_weights('../saved_agent/learned_self_proposed0_critic.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
