{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../../module/')\n",
    "\n",
    "from keras2.models import Model\n",
    "from keras2.layers import concatenate, Dense, Input, Flatten\n",
    "from keras2.optimizers import Adam\n",
    "import csv\n",
    "from util import *\n",
    "import gym2\n",
    "from rl2.agents import selfDDPGAgent, selfDDPGAgent2\n",
    "from rl2.memory import SequentialMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GymのPendulum環境を作成\n",
    "env = gym2.make(\"Pendulum-v2\")\n",
    "\n",
    "# 取りうる”打ち手”のアクション数と値の定義\n",
    "nb_actios = 2\n",
    "ACT_ID_TO_VALUE = {0: [-1], 1: [+1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def critic_net(a_shape , s_shape):\n",
    "    action_input = Input(a_shape)\n",
    "    observation_input = Input(shape=(1,)+s_shape)\n",
    "    flattened_observation = Flatten()(observation_input)\n",
    "    x = concatenate([action_input, flattened_observation])\n",
    "    x = Dense(16, activation=\"relu\")(x)\n",
    "    x = Dense(16, activation=\"relu\")(x)\n",
    "    x = Dense(1, activation=\"linear\")(x)\n",
    "    critic = Model(inputs=[action_input, observation_input], outputs=x)\n",
    "    return (critic, action_input)\n",
    "\n",
    "def branch_actor(a_shape, s_shape):\n",
    "    action_input = Input(shape=(1,)+s_shape)\n",
    "    x = Flatten()(action_input) # 実質的なinput layer\n",
    "    \n",
    "    x1 = Dense(8, activation=\"relu\")(x)\n",
    "    x1 = Dense(8, activation=\"relu\")(x1)\n",
    "    x1 = Dense(1, activation=\"multiple_tanh\")(x1) # action signal\n",
    "    \n",
    "    x2 = Dense(8, activation=\"relu\")(x)\n",
    "    x2 = Dense(8, activation=\"relu\")(x2)\n",
    "    x2 = Dense(1, activation=\"tau_output\")(x2) # tau\n",
    "    \n",
    "    output = concatenate([x1, x2])\n",
    "    actor = Model(inputs=action_input, outputs=output)\n",
    "    return actor\n",
    "\n",
    "\n",
    "def agent2(a_shape, s_shape):\n",
    "    actor = branch_actor(a_shape, s_shape)\n",
    "    critic,  critic_action_input = critic_net(a_shape, s_shape)\n",
    "    memory = SequentialMemory(limit = 50000, window_length = 1)\n",
    "    agent = selfDDPGAgent2(\n",
    "        a_shape[0],\n",
    "        actor,\n",
    "        critic,\n",
    "        critic_action_input,\n",
    "        memory,\n",
    "        original_noise=True,\n",
    "        action_clipper=[-10., 10.],\n",
    "        tau_clipper=[0.001, 1.],\n",
    "        params_logging=False,\n",
    "        gradient_logging=False,\n",
    "        batch_size=128,\n",
    "    )\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From ../../../module/keras2/backend/tensorflow_backend.py:82: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../../module/keras2/backend/tensorflow_backend.py:525: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../../module/keras2/backend/tensorflow_backend.py:4148: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../../module/keras2/backend/tensorflow_backend.py:182: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../../module/keras2/backend/tensorflow_backend.py:189: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../../module/keras2/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# agent compilation\n",
    "l = 1.\n",
    "step = 50000  # num of interval\n",
    "episode_step = step\n",
    "a = agent2((2,), (2,))\n",
    "actor_optimizer, critic_optimizer = Adam(lr=100., clipnorm=1.), Adam(lr=0.001, clipnorm=1.) # actorの方は何でもいい\n",
    "optimizer = [actor_optimizer, critic_optimizer]\n",
    "a.compile(optimizer=optimizer, metrics=[\"mse\"], action_lr=0.0001, tau_lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent setup\n",
    "a.actor.load_weights('../saved_agent/learned_self2.h5')\n",
    "a.training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.0365186640168\n",
      "41.353278248899464\n",
      "45.326320180710766\n",
      "45.308906383311836\n",
      "43.89239593328374\n",
      "45.38764063603252\n",
      "45.11560062473757\n",
      "39.857690200576094\n",
      "43.95941883337839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# experiment\n",
    "\n",
    "l = 1.\n",
    "\n",
    "view_path = False\n",
    "cycle = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "# step wise evaluation\n",
    "\n",
    "step_limit = 50000\n",
    "n_episodes = 50\n",
    "gamma = .99\n",
    "average_reward = 0\n",
    "\n",
    "\n",
    "for ep in range(n_episodes):\n",
    "    state_log = []\n",
    "    env.reset()\n",
    "    episode_reward = 0\n",
    "    for steps in range(step_limit):\n",
    "        reward = 0\n",
    "        x = env.state\n",
    "        a_agent, tau = a.forward(x)\n",
    "        state_log.append(x)\n",
    "        action_repetition = int(np.ceil(20 * tau))  # minimum natural number which makes `dt` smaller than 0.005\n",
    "        dt = tau / action_repetition\n",
    "        for p in range(action_repetition):\n",
    "            _,_,r,_ = env.step(np.array([a_agent]), dt, tau)\n",
    "            reward += r\n",
    "        reward *= dt\n",
    "        reward += - 0.01 * a_agent**2 + l * tau # step reward\n",
    "\n",
    "        episode_reward += pow(gamma, steps) * reward\n",
    "    print(episode_reward)\n",
    "    average_reward += episode_reward / n_episodes\n",
    "    state_log = np.array(state_log)\n",
    "    if view_path:\n",
    "        plt.plot(state_log[:,0], state_log[:,1], alpha=0.4, color=cycle[ep])\n",
    "        plt.scatter(state_log[0,0], state_log[0,1], marker='o', color=cycle[ep])\n",
    "        plt.scatter(state_log[-1,0], state_log[-1,1], marker='x', color=cycle[ep])\n",
    "\n",
    "if view_path:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-18.4901533799546\n"
     ]
    }
   ],
   "source": [
    "print(average_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good_agentはどうなん？"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
