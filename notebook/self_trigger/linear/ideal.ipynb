{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../../module/')\n",
    "\n",
    "from keras2.models import Model\n",
    "from keras2.layers import concatenate, Dense, Input, Flatten\n",
    "from keras2.optimizers import Adam, Optimizer\n",
    "import keras2.backend as K\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "import itertools\n",
    "from util import *\n",
    "import gym2\n",
    "from rl2.agents import selfDDPGAgent, selfDDPGAgent2, selfDDPGAgent3\n",
    "from rl2.memory import SequentialMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym2.make('Linear-v1')\n",
    "Q = .01 * np.eye(2)\n",
    "R = .01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def critic_net(a_shape , s_shape):\n",
    "    action_input = Input(a_shape)\n",
    "    observation_input = Input(shape=(1,)+s_shape)\n",
    "    flattened_observation = Flatten()(observation_input)\n",
    "    x = concatenate([action_input, flattened_observation])\n",
    "    x = Dense(16, activation=\"relu\")(x)\n",
    "    x = Dense(16, activation=\"relu\")(x)\n",
    "    x = Dense(1, activation=\"linear\")(x)\n",
    "    critic = Model(inputs=[action_input, observation_input], outputs=x)\n",
    "    return (critic, action_input)\n",
    "\n",
    "def value_net(s_shape):\n",
    "    state_input = Input((1,)+s_shape)\n",
    "    x = Flatten()(state_input)\n",
    "    \n",
    "    x = Dense(16, activation='relu')(x)\n",
    "    x = Dense(16, activation='relu')(x)\n",
    "    x = Dense(1, activation=\"linear\")(x)\n",
    "    value = Model(inputs=state_input, output=x)\n",
    "    return value\n",
    "\n",
    "def branch_actor(a_shape, s_shape):\n",
    "    action_input = Input(shape=(1,)+s_shape)\n",
    "    x = Flatten()(action_input) # 実質的なinput layer\n",
    "    \n",
    "    x1 = Dense(16, activation=\"relu\")(x)\n",
    "    x1 = Dense(16, activation=\"relu\")(x1)\n",
    "    x1 = Dense(1, activation=\"multiple_tanh\")(x1) # action signal\n",
    "    \n",
    "    x2 = Dense(16, activation=\"relu\")(x)\n",
    "    x2 = Dense(16, activation=\"relu\")(x2)\n",
    "    x2 = Dense(1, activation=\"tau_output_large\")(x2) # tau\n",
    "    \n",
    "    output = concatenate([x1, x2])\n",
    "    actor = Model(inputs=action_input, outputs=output)\n",
    "    return actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_optimizer = Optimizer()\n",
    "def q_gradient(state, actor, critic):\n",
    "    params = actor.trainable_weights\n",
    "    \n",
    "    # tensor\n",
    "    state_input = tf.placeholder(tf.float32, shape=(None, 1, 2))\n",
    "    actor_output = actor(state_input)\n",
    "    combined_input_tensor = [actor_output, state_input]\n",
    "    critic_output_tensor = critic(combined_input_tensor)\n",
    "    loss = -K.mean(critic_output_tensor)\n",
    "    gradient_tensor = dummy_optimizer.get_gradients(loss, params)\n",
    "    \n",
    "    # calc\n",
    "    grad_calc_func = K.function([combined_input_tensor[1]], gradient_tensor)\n",
    "    q_g = grad_calc_func([state])\n",
    "\n",
    "    return q_g\n",
    "\n",
    "# Adam クラス\n",
    "def learning_rate_arr(actor, size=674, u_lr=.00001, tau_lr=.0001):\n",
    "    grad_idx = 0\n",
    "    i, j = 0, 0\n",
    "    lrs = np.zeros((size,))\n",
    "    for layer in actor.layers:\n",
    "        if len(layer.get_weights())==0:\n",
    "            continue\n",
    "        else:\n",
    "            w, b = layer.get_weights()\n",
    "            grad_idx += len(w.ravel()) + len(b.ravel())\n",
    "            if j % 2 == 0: # u\n",
    "                lrs[i:grad_idx] = u_lr\n",
    "            else: # tau\n",
    "                lrs[i:grad_idx] = tau_lr\n",
    "            i = grad_idx\n",
    "            j += 1\n",
    "    return lrs\n",
    "\n",
    "    \n",
    "def flatten_gradient(gradient):\n",
    "    params = []\n",
    "    for i in range(len(gradient)//2):\n",
    "        w, b = gradient[2*i], gradient[2*i+1]\n",
    "        layer_params = np.hstack((w.ravel(), b.ravel()))\n",
    "        params = np.hstack((params, layer_params))\n",
    "    params = np.array(params).ravel()\n",
    "    return params\n",
    "\n",
    "\n",
    "def get_nn_params(actor):\n",
    "    params = []\n",
    "    for layer in actor.layers:\n",
    "        if len(layer.get_weights())==0:\n",
    "            continue\n",
    "        else:\n",
    "            w, b = layer.get_weights()\n",
    "            layer_params = np.hstack((w.ravel(), b.ravel()))\n",
    "            params = np.hstack((params, layer_params))\n",
    "    params = np.array(params).ravel()\n",
    "    return params\n",
    "\n",
    "def set_nn_params(actor, params):\n",
    "    param_idx = 0\n",
    "    for layer in actor.layers:\n",
    "        if len(layer.get_weights())==0:\n",
    "            continue\n",
    "        else:\n",
    "            w, b = layer.get_weights()\n",
    "            # set w\n",
    "            w_prime = params[param_idx:param_idx+w.ravel().shape[0]].reshape(w.shape)\n",
    "            param_idx += w.ravel().shape[0]\n",
    "\n",
    "            # set b\n",
    "            b_prime = params[param_idx:param_idx+b.ravel().shape[0]].reshape(b.shape)\n",
    "            param_idx += b.ravel().shape[0]\n",
    "\n",
    "            layer.set_weights([w_prime, b_prime])\n",
    "    assert params.shape[0] == param_idx\n",
    "    return actor\n",
    "\n",
    "class Adam():\n",
    "    def __init__(self, lrs, beta_1=.9, beta_2=.999, epsilon=1e-6):\n",
    "        self.lrs = lrs # 学習率\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "        self.m = np.zeros(674,) # 前回の勾配\n",
    "        self.v = np.zeros(674,) # 前回の勾配\n",
    "    \n",
    "    def update(self, actor, pg):\n",
    "        # update m\n",
    "        self.m = (self.beta_1 * self.m) + (1. - self.beta_1) * pg\n",
    "        \n",
    "        # update v\n",
    "        self.v = (self.beta_2 * self.v) + (1. - self.beta_2) * pg**2\n",
    "        \n",
    "        # 更新量を決める\n",
    "        ag = self.lrs * self.m / (np.sqrt(self.v) + self.epsilon)\n",
    "        \n",
    "        # 今のパラメータ\n",
    "        ps = _get_nn_params(actor)\n",
    "        \n",
    "        # update\n",
    "        ps = ps - ag\n",
    "        \n",
    "        # update\n",
    "        actor = _set_nn_params(actor, ps)\n",
    "    \n",
    "        return actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "alpha = 0.4\n",
    "beta = 1.\n",
    "\n",
    "# 1ステップのインタラクション\n",
    "def interaction(state, u, tau, env):\n",
    "    env.reset()\n",
    "    x = np.array(state)\n",
    "    env.set_state(x)\n",
    "    reward = 0\n",
    "    a_agent, tau = u, tau\n",
    "    tau = np.clip(tau, 0.01, 10.)\n",
    "    action_repetition = int(np.ceil(100 * tau))  # minimum natural number which makes `dt` smaller than 0.005\n",
    "    dt = .01\n",
    "    for p in range(action_repetition):\n",
    "        _,r,_,_ = env.step(np.array([a_agent]), dt, tau, 0)\n",
    "        r *= np.exp(- alpha * p * dt)\n",
    "        reward += r\n",
    "    reward *= dt\n",
    "    reward -= beta\n",
    "    state1 = env.state\n",
    "    return reward, state1\n",
    "\n",
    "\n",
    "# 学習データ\n",
    "def train_data(actor):\n",
    "    memory = []\n",
    "    S1 = np.linspace(-7, 7, 10)\n",
    "    S2 = np.linspace(-7, 7, 10)\n",
    "    S1, S2 = np.meshgrid(S1, S2)\n",
    "    S1, S2 = S1.flatten(), S2.flatten()\n",
    "\n",
    "    for i, x in enumerate(zip(S1, S2)):\n",
    "        state0 = np.array(x)\n",
    "        a_agent, tau = actor.predict_on_batch(state0.reshape((1,1,)+state0.shape))[0]\n",
    "        reward, state1 = interaction(state0, a_agent, tau, env)\n",
    "        memory.append([state0, np.array([a_agent, tau]), reward, state1])\n",
    "    memory = np.array(memory)\n",
    "    return memory\n",
    "\n",
    "# Q関数の学習\n",
    "def td_learning(memory, actor, critic):\n",
    "    # TODO: loss小さい=関数として正しい　をチェックする\n",
    "    assert critic.compile, 'compile critic before use this function'\n",
    "    # critic learning\n",
    "    epoch = 10\n",
    "    batch_size = 32\n",
    "    arr = np.array(range(memory.shape[0]))\n",
    "    losses = []\n",
    "    for _ in range(epoch):\n",
    "        # make mini_batch\n",
    "        mem = memory[np.random.choice(arr, batch_size, replace=False)]\n",
    "        state0_batch = []\n",
    "        action_batch = []\n",
    "        reward_batch = []\n",
    "        state1_batch = []\n",
    "        for m in mem:\n",
    "            state0_batch.append([m[0]])\n",
    "            action_batch.append(m[1])\n",
    "            reward_batch.append([m[2]])\n",
    "            state1_batch.append([m[3]])\n",
    "        state0_batch, action_batch, reward_batch, state1_batch = \\\n",
    "        np.array(state0_batch), np.array(action_batch), np.array(reward_batch), np.array(state1_batch)\n",
    "\n",
    "        # TD error\n",
    "        next_action = actor.predict_on_batch(state1_batch)\n",
    "        state1_batch_with_action = [next_action, state1_batch]\n",
    "        target = critic.predict_on_batch(state1_batch_with_action)\n",
    "        discount = np.exp(- alpha * action_batch[:,1].reshape(batch_size, 1))\n",
    "        r_second = np.multiply(discount, target)\n",
    "        r = reward_batch + r_second\n",
    "\n",
    "        # learn\n",
    "        critic_input_batch = [action_batch, state0_batch]\n",
    "        loss = critic.train_on_batch(critic_input_batch, r)\n",
    "    return critic, loss\n",
    "\n",
    "# 勾配の計算\n",
    "def policy_gradient(actor, critic):\n",
    "    # どの状態からの変化を見る？\n",
    "    init_state = np.array([1,2])\n",
    "    # 初期状態からのシミュレーション\n",
    "    x = init_state\n",
    "    episode_time = 0\n",
    "    log = []\n",
    "    while True:\n",
    "        a_agent, tau = actor.predict_on_batch(x.reshape(1,1,2))[0]\n",
    "        log.append([x, episode_time])\n",
    "        reward, x = interaction(x, a_agent, tau, env)\n",
    "        episode_time += tau\n",
    "        if episode_time >= 1.:\n",
    "            log.append([x, episode_time])\n",
    "            break\n",
    "    \n",
    "    pg = 0\n",
    "    # Q 関数の勾配を計算する\n",
    "    for x, t in log:\n",
    "        g = q_gradient([x], actor, critic)\n",
    "        g = flatten_gradient(g)\n",
    "        g *= np.exp(- alpha * t)\n",
    "        pg += g\n",
    "    return pg\n",
    "\n",
    "# 評価\n",
    "def evaluation(actor):\n",
    "    value = 1\n",
    "    return value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor = branch_actor((2,),(2,))\n",
    "critic = critic_net((2,),(2,))[0]\n",
    "critic.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n",
      "q_n\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-53ece66e7911>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mlearned_q_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtd_learning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcritic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'q_n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mpg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcritic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mactor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-6a177e18335b>\u001b[0m in \u001b[0;36mpolicy_gradient\u001b[0;34m(actor, critic)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;31m# Q 関数の勾配を計算する\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcritic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mg\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-c079875296b4>\u001b[0m in \u001b[0;36mq_gradient\u001b[0;34m(state, actor, critic)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# calc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mgrad_calc_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcombined_input_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mq_g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_calc_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mq_g\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/studyM2/projects/eventddpg/module/keras2/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2728\u001b[0m             \u001b[0;31m# のここ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2729\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2730\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2731\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/studyM2/projects/eventddpg/module/keras2/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2681\u001b[0m                                 \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2682\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2683\u001b[0;31m                                 session)\n\u001b[0m\u001b[1;32m   2684\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2685\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/studyM2/projects/eventddpg/module/keras2/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_make_callable\u001b[0;34m(self, feed_arrays, feed_symbols, symbol_vals, session)\u001b[0m\n\u001b[1;32m   2633\u001b[0m             \u001b[0mcallable_opts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2634\u001b[0m         \u001b[0;31m# Create callable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2635\u001b[0;31m         \u001b[0mcallable_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable_from_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallable_opts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2636\u001b[0m         \u001b[0;31m# Cache parameters corresponding to the generated callable, so that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2637\u001b[0m         \u001b[0;31m# we can detect future mismatches and refresh the callable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.4/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_make_callable_from_options\u001b[0;34m(self, callable_options)\u001b[0m\n\u001b[1;32m   1486\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnew\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1487\u001b[0m     \"\"\"\n\u001b[0;32m-> 1488\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1489\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mBaseSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallable_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.4/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1372\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m       \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m   \u001b[0;31m# The threshold to run garbage collection to delete dead tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "actor.load_weights('../saved_agent/linear_init_extend_actor.h5')\n",
    "lrs = learning_rate_arr(actor, size=674, u_lr=.00001, tau_lr=.0001)\n",
    "opt = Adam(lrs)\n",
    "for i in range(10):\n",
    "    d_train = train_data(actor)\n",
    "    print('data')\n",
    "    learned_q_net, loss = td_learning(d_train, actor, critic)\n",
    "    print('q_n')\n",
    "    pg = policy_gradient(actor, critic)\n",
    "    print('pg')\n",
    "    actor = opt.update(actor, pg)\n",
    "    print('adam')\n",
    "    ev = evaluation(actor)\n",
    "    print(i, ev, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 501 ms, sys: 12.5 ms, total: 513 ms\n",
      "Wall time: 540 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "state = np.array([[1,2]])\n",
    "qg = q_gradient(state, actor, critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 311 µs, sys: 132 µs, total: 443 µs\n",
      "Wall time: 428 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "g = flatten_gradient(qg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.39446598e-01,  8.08119923e-02,  0.00000000e+00,  0.00000000e+00,\n",
       "       -7.81188458e-02, -1.96768388e-01,  1.54914409e-01,  0.00000000e+00,\n",
       "       -2.50273287e-01, -2.97086030e-01,  0.00000000e+00,  5.94549596e-01,\n",
       "       -1.71956420e-02, -3.93255949e-02,  0.00000000e+00, -4.06553000e-01,\n",
       "        8.78893197e-01,  1.61623985e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "       -1.56237692e-01, -3.93536776e-01,  3.09828818e-01,  0.00000000e+00,\n",
       "       -5.00546575e-01, -5.94172060e-01,  0.00000000e+00,  1.18909919e+00,\n",
       "       -3.43912840e-02, -7.86511898e-02,  0.00000000e+00, -8.13106000e-01,\n",
       "        4.39446598e-01,  8.08119923e-02, -0.00000000e+00, -0.00000000e+00,\n",
       "       -7.81188458e-02, -1.96768388e-01,  1.54914409e-01,  0.00000000e+00,\n",
       "       -2.50273287e-01, -2.97086030e-01,  0.00000000e+00,  5.94549596e-01,\n",
       "       -1.71956420e-02, -3.93255949e-02, -0.00000000e+00, -4.06553000e-01,\n",
       "       -2.39064448e-08,  0.00000000e+00, -2.83665322e-08, -3.95387048e-08,\n",
       "        0.00000000e+00, -2.17384208e-08,  0.00000000e+00, -7.87345744e-10,\n",
       "        0.00000000e+00, -4.72370978e-08,  0.00000000e+00, -1.63196887e-08,\n",
       "       -2.14036344e-08,  0.00000000e+00, -4.23865529e-08,  0.00000000e+00,\n",
       "       -4.78128896e-08,  0.00000000e+00, -5.67330645e-08, -7.90774095e-08,\n",
       "        0.00000000e+00, -4.34768417e-08,  0.00000000e+00, -1.57469149e-09,\n",
       "        0.00000000e+00, -9.44741956e-08,  0.00000000e+00, -3.26393774e-08,\n",
       "       -4.28072688e-08,  0.00000000e+00, -8.47731059e-08,  0.00000000e+00,\n",
       "       -2.39064448e-08, -0.00000000e+00, -2.83665322e-08, -3.95387048e-08,\n",
       "       -0.00000000e+00, -2.17384208e-08,  0.00000000e+00, -7.87345744e-10,\n",
       "       -0.00000000e+00, -4.72370978e-08, -0.00000000e+00, -1.63196887e-08,\n",
       "       -2.14036344e-08, -0.00000000e+00, -4.23865529e-08, -0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  7.34444484e-02,\n",
       "        0.00000000e+00, -6.85752213e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  1.20118988e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -1.07653546e+00,  0.00000000e+00, -1.89120159e-01,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  6.72896877e-02,\n",
       "        0.00000000e+00, -6.28285170e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  1.10052836e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -9.86320138e-01,  0.00000000e+00, -1.73271596e-01,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.88710466e-02,\n",
       "        0.00000000e+00, -1.76199332e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  3.08637530e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "       -2.76608407e-01,  0.00000000e+00, -4.85931262e-02,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.85895730e-02,\n",
       "        0.00000000e+00, -1.73571199e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  3.04033965e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "       -2.72482604e-01,  0.00000000e+00, -4.78683263e-02,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  6.81595504e-03,\n",
       "        0.00000000e+00, -6.36407062e-02,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  1.11475505e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "       -9.99070406e-02,  0.00000000e+00, -1.75511502e-02,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  2.09925622e-02,\n",
       "        0.00000000e+00, -1.96007967e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  3.43335062e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "       -3.07705194e-01,  0.00000000e+00, -5.40560484e-02,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  3.79236415e-02,\n",
       "        0.00000000e+00, -3.54093790e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  6.20244265e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "       -5.55877864e-01,  0.00000000e+00, -9.76537392e-02,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  5.79046793e-02,\n",
       "        0.00000000e+00, -5.40657163e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  9.47035789e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "       -8.48756373e-01,  0.00000000e+00, -1.49105117e-01,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  3.81744554e-04,\n",
       "        0.00000000e+00, -3.56435636e-03,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  6.24346361e-03,  0.00000000e+00,  0.00000000e+00,\n",
       "       -5.59554296e-03,  0.00000000e+00, -9.82995960e-04,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  5.07784933e-02,\n",
       "        0.00000000e+00, -4.74119812e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  8.30486417e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "       -7.44301975e-01,  0.00000000e+00, -1.30755112e-01,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  5.35060130e-02,\n",
       "        0.00000000e+00, -4.99586701e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  8.75095189e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "       -7.84281433e-01,  0.00000000e+00, -1.37778491e-01,  0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,  5.76242469e-02,\n",
       "       -0.00000000e+00, -5.38038731e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00,  9.42449272e-01,  0.00000000e+00, -0.00000000e+00,\n",
       "       -8.44645798e-01,  0.00000000e+00, -1.48382992e-01, -0.00000000e+00,\n",
       "       -1.70003069e-08, -7.49041806e-09, -1.07782823e-08, -9.31404109e-09,\n",
       "        0.00000000e+00, -4.62488003e-09,  0.00000000e+00,  0.00000000e+00,\n",
       "       -8.65775451e-09,  0.00000000e+00,  1.86300997e-09,  5.35152367e-09,\n",
       "        1.05598343e-10, -6.29556984e-09,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -1.57655204e-08, -6.94636526e-09, -9.99542138e-09, -8.63753247e-09,\n",
       "        0.00000000e+00, -4.28896030e-09,  0.00000000e+00,  0.00000000e+00,\n",
       "       -8.02891442e-09,  0.00000000e+00,  1.72769365e-09,  4.96282571e-09,\n",
       "        9.79284015e-11, -5.83830273e-09,  0.00000000e+00,  0.00000000e+00,\n",
       "       -1.89007920e-08, -8.32778113e-09, -1.19831993e-08, -1.03552695e-08,\n",
       "        0.00000000e+00, -5.14190113e-09,  0.00000000e+00,  0.00000000e+00,\n",
       "       -9.62561586e-09,  0.00000000e+00,  2.07127804e-09,  5.94977712e-09,\n",
       "        1.17403309e-10, -6.99935931e-09,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -2.15884413e-08, -9.51197254e-09, -1.36871829e-08, -1.18277645e-08,\n",
       "        0.00000000e+00, -5.87306737e-09,  0.00000000e+00,  0.00000000e+00,\n",
       "       -1.09943556e-08,  0.00000000e+00,  2.36580910e-09,  6.79582168e-09,\n",
       "        1.34097788e-10, -7.99465205e-09,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -2.26879120e-08, -9.99640459e-09, -1.43842529e-08, -1.24301369e-08,\n",
       "        0.00000000e+00, -6.17217477e-09,  0.00000000e+00,  0.00000000e+00,\n",
       "       -1.15542838e-08,  0.00000000e+00,  2.48629650e-09,  7.14192394e-09,\n",
       "        1.40927214e-10, -8.40180903e-09,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -5.76885455e-08, -2.54178545e-08, -3.65748356e-08, -3.16061062e-08,\n",
       "        0.00000000e+00, -1.56939866e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "       -2.93790752e-08,  0.00000000e+00,  6.32190567e-09,  1.81597670e-08,\n",
       "        3.58335583e-10, -2.13632774e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -1.19745671e-08, -5.27605248e-09, -7.59193686e-09, -6.56056409e-09,\n",
       "        0.00000000e+00, -3.25764327e-09,  0.00000000e+00,  0.00000000e+00,\n",
       "       -6.09829343e-09,  0.00000000e+00,  1.31225497e-09,  3.76947185e-09,\n",
       "        7.43806822e-11, -4.43443282e-09,  0.00000000e+00,  0.00000000e+00,\n",
       "       -4.04915497e-08, -1.78407742e-08, -2.56718504e-08, -2.21843024e-08,\n",
       "        0.00000000e+00, -1.10155982e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "       -2.06211510e-08,  0.00000000e+00,  4.43734072e-09,  1.27463275e-08,\n",
       "        2.51515475e-10, -1.49948693e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -3.17845625e-08, -1.40044341e-08, -2.01515764e-08, -1.74139636e-08,\n",
       "        0.00000000e+00, -8.64689031e-09,  0.00000000e+00,  0.00000000e+00,\n",
       "       -1.61869398e-08,  0.00000000e+00,  3.48316975e-09,  1.00054569e-08,\n",
       "        1.97431557e-10, -1.17704895e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -2.64648961e-08, -1.16605623e-08, -1.67788805e-08, -1.44994514e-08,\n",
       "        0.00000000e+00, -7.19969151e-09,  0.00000000e+00,  0.00000000e+00,\n",
       "       -1.34777904e-08,  0.00000000e+00,  2.90020430e-09,  8.33087999e-09,\n",
       "        1.64388156e-10, -9.80050530e-09, -0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -5.72000802e-01,\n",
       "        0.00000000e+00, -3.45176190e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00, -1.55712271e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -6.02400005e-01,  0.00000000e+00, -4.51320708e-01,  0.00000000e+00,\n",
       "       -1.63062620e+00,  8.99825565e-08,  2.91571620e-08,  4.35859135e-08,\n",
       "        7.96082560e-08,  0.00000000e+00,  3.28712737e-08,  0.00000000e+00,\n",
       "        0.00000000e+00,  5.09881062e-08,  0.00000000e+00,  4.65017758e-09,\n",
       "        1.25580735e-09,  1.22260480e-09,  2.35771243e-08,  0.00000000e+00,\n",
       "        0.00000000e+00,  1.86940063e-08])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten_gradient(qg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "an = np.array([[1,2],[3,4,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "an = np.resize(an,(5,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([1, 2]), list([3, 4, 5]), list([1, 2]), list([3, 4, 5]),\n",
       "       list([1, 2])], dtype=object)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
